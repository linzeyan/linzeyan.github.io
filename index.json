[{"categories":null,"contents":" Lookup # List all plugins ansible-doc -t lookup -l # Use `ansible-doc -t lookup \u0026lt;plugin\u0026gt;` to see detail ansible-doc -t lookup ping winrm - console output 在 hyper-v 那台機器 Enable Winrm 之後 一直出現下面的錯誤。 在 group 加上一行即可\nansible_winrm_transport=ntlm\nhyper-v01 | UNREACHABLE! =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;ssl: the specified credentials were rejected by the server\u0026#34;, \u0026#34;unreachable\u0026#34;: true } - /etc/ansible/hosts ansible_user=administrator ansible_password=password ansible_port=5986 ansible_connection=winrm ansible_winrm_server_cert_validation=ignore ansible_winrm_transport=ntlm ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/ansible/","summary":" Lookup # List all plugins ansible-doc -t lookup -l # Use `ansible-doc -t lookup \u0026lt;plugin\u0026gt;` to see detail ansible-doc -t lookup ping winrm - console output 在 hyper-v 那台機器 Enable Winrm 之後 一直出現下面的錯誤。 在 group 加上一行即可\nansible_winrm_transport=ntlm\nhyper-v01 | UNREACHABLE! =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;ssl: the specified credentials were rejected by the server\u0026#34;, \u0026#34;unreachable\u0026#34;: true } - /etc/ansible/hosts ansible_user=administrator ansible_password=password ansible_port=5986 ansible_connection=winrm ansible_winrm_server_cert_validation=ignore ansible_winrm_transport=ntlm ","tags":null,"title":"Ansible Command"},{"categories":null,"contents":" CloudFront # list distributions aws cloudfront list-distributions --query \u0026#39;*.Items[*].[Comment,Id,Aliases.Items[0],DefaultCacheBehavior.TargetOriginId]\u0026#39; --output table # create invalidation aws cloudfront create-invalidation --distribution-id EATDVGD171BHDS1 --paths \u0026#34;/*\u0026#34; ## check cloudfornt log enable or not for i in $(aws cloudfront list-distributions --output table --query \u0026#39;DistributionList.Items[*].Id\u0026#39; --profile route53 | sed \u0026#39;1,3d;$d\u0026#39; | awk \u0026#39;{print $2}\u0026#39;) do result=$(aws cloudfront get-distribution --id ${i} --query \u0026#39;Distribution.DistributionConfig.Logging\u0026#39; --profile route53 | jq .Enabled) if [[ \u0026#34;${result}\u0026#34; != \u0026#34;true\u0026#34; ]];then echo ${i} fi done EC2 # list aws ec2 describe-instances --query \u0026#39;Reservations[*].Instances[*].[Tags[0].Value,InstanceId]\u0026#39; --output table --page-size 100 ECR # Get password and login to 12345.dkr.ecr.ap-northeast-1.amazonaws.com aws ecr get-login-password | docker login --username AWS --password-stdin 12345.dkr.ecr.ap-northeast-1.amazonaws.com S3 # Copy local file to S3 aws s3 cp ./pic.png s3://bucket_name/dir/ # Sync local local_dir to S3 aws s3 sync local_dir s3://bucket_name --exclude \u0026#39;gameConfig.json\u0026#39; --acl public-read --delete snapshot # list aws ec2 describe-snapshots \\ --owner-ids self \\ --query \u0026#34;Snapshots[?(Tags[0].Value==\u0026#39;backend\u0026#39;)].[SnapshotId,VolumeId]\u0026#34; \\ --region ap-northeast-1 # create aws ec2 create-snapshot --volume-id vol-02468851c2bc3bc4b --description \u0026#34;gitlab-$(date +%F)\u0026#34; --region ap-northeast-1 # delete aws ec2 delete-snapshot --snapshot-id snap-1234567890abcdef0 --region ap-northeast-1 sns region=\u0026#39;ap-east-1\u0026#39; account_id=\u0026#39;888886666321\u0026#39; topic=\u0026#39;sa\u0026#39; # create topic aws sns create-topic --name ${topic} # subscribe aws sns subscribe --topic-arn arn:aws:sns:${region}:${account_id}:${topic} --protocol email --notification-endpoint ricky@gmail.com # list aws sns list-subscriptions-by-topic --topic-arn arn:aws:sns:${region}:${account_id}:${topic} # create alarm ### metric-name ##CPUUtilization --\u0026gt;percent ##NetworkIn --\u0026gt;bytes ##NetworkOut --\u0026gt;bytes for line in $(aws ec2 describe-instances --query \u0026#39;Reservations[*].Instances[*].[Tags[0].Value,InstanceId]\u0026#39; --output table --page-size 100) do ID=$(echo ${line}|awk -F \u0026#39;,\u0026#39; \u0026#39;{print $1}\u0026#39;) VALUE=$(echo ${line}|awk -F \u0026#39;,\u0026#39; \u0026#39;{print $2}\u0026#39;) aws cloudwatch put-metric-alarm \\ --alarm-name ${ID}_netout \\ --metric-name NetworkOut \\ --namespace AWS/EC2 \\ --statistic Average \\ --period 300 \\ --threshold 2560000 \\ --comparison-operator GreaterThanOrEqualToThreshold \\ --dimensions \u0026#34;Name=InstanceId,Value=${VALUE}\u0026#34; \\ --evaluation-periods 3 \\ --alarm-actions arn:aws:sns:${region}:${account_id}:${topic} ##--unit Bytes echo \u0026#34;$ID done\u0026#34; done WAF aws wafv2 create-web-acl \\ --name acl_name \\ --scope CLOUDFRONT \\ --default-action Allow={} \\ --visibility-config SampledRequestsEnabled=true,CloudWatchMetricsEnabled=true,MetricName=metric_acl_name \\ --rule ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/aws/command/","summary":"CloudFront # list distributions aws cloudfront list-distributions --query \u0026#39;*.Items[*].[Comment,Id,Aliases.Items[0],DefaultCacheBehavior.TargetOriginId]\u0026#39; --output table # create invalidation aws cloudfront create-invalidation --distribution-id EATDVGD171BHDS1 --paths \u0026#34;/*\u0026#34; ## check cloudfornt log enable or not for i in $(aws cloudfront list-distributions --output table --query \u0026#39;DistributionList.Items[*].Id\u0026#39; --profile route53 | sed \u0026#39;1,3d;$d\u0026#39; | awk \u0026#39;{print $2}\u0026#39;) do result=$(aws cloudfront get-distribution --id ${i} --query \u0026#39;Distribution.DistributionConfig.Logging\u0026#39; --profile route53 | jq .Enabled) if [[ \u0026#34;${result}\u0026#34; != \u0026#34;true\u0026#34; ]];then echo ${i} fi done EC2 # list aws ec2 describe-instances --query \u0026#39;Reservations[*].","tags":null,"title":"AWS Command"},{"categories":null,"contents":" S3 Bucket Policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowPublicRead\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::bucketName/*\u0026#34; } ] } S3 CORS [ { \u0026#34;AllowedHeaders\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;AllowedMethods\u0026#34;: [\u0026#34;GET\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;DELETE\u0026#34;], \u0026#34;AllowedOrigins\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;ExposeHeaders\u0026#34;: [ \u0026#34;x-amz-server-side-encryption\u0026#34;, \u0026#34;x-amz-request-id\u0026#34;, \u0026#34;x-amz-id-2\u0026#34; ], \u0026#34;MaxAgeSeconds\u0026#34;: 3000 } ] ECR Lifecycle Policy { \u0026#34;rules\u0026#34;: [ { \u0026#34;rulePriority\u0026#34;: 1, \u0026#34;description\u0026#34;: \u0026#34;Keep only the last 100 images\u0026#34;, \u0026#34;selection\u0026#34;: { \u0026#34;tagStatus\u0026#34;: \u0026#34;any\u0026#34;, \u0026#34;countType\u0026#34;: \u0026#34;imageCountMoreThan\u0026#34;, \u0026#34;countNumber\u0026#34;: 100 }, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;expire\u0026#34; } } ] } ECR Lifecycle Policy1 { \u0026#34;rules\u0026#34;: [ { \u0026#34;rulePriority\u0026#34;: 1, \u0026#34;description\u0026#34;: \u0026#34;Remove images with certain tag\u0026#34;, \u0026#34;selection\u0026#34;: { \u0026#34;tagStatus\u0026#34;: \u0026#34;tagged\u0026#34;, \u0026#34;tagPrefixList\u0026#34;: [\u0026#34;tag1\u0026#34;, \u0026#34;tag2\u0026#34;], \u0026#34;countType\u0026#34;: \u0026#34;imageCountMoreThan\u0026#34;, \u0026#34;countNumber\u0026#34;: 0 }, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;expire\u0026#34; } } ] } ECR Lifecycle Policy2 { \u0026#34;rules\u0026#34;: [ { \u0026#34;rulePriority\u0026#34;: 1, \u0026#34;description\u0026#34;: \u0026#34;Remove untagged images older than 14 days\u0026#34;, \u0026#34;selection\u0026#34;: { \u0026#34;tagStatus\u0026#34;: \u0026#34;untagged\u0026#34;, \u0026#34;countType\u0026#34;: \u0026#34;sinceImagePushed\u0026#34;, \u0026#34;countUnit\u0026#34;: \u0026#34;days\u0026#34;, \u0026#34;countNumber\u0026#34;: 14 }, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;expire\u0026#34; } } ] } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/aws/configure/","summary":" S3 Bucket Policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowPublicRead\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::bucketName/*\u0026#34; } ] } S3 CORS [ { \u0026#34;AllowedHeaders\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;AllowedMethods\u0026#34;: [\u0026#34;GET\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;DELETE\u0026#34;], \u0026#34;AllowedOrigins\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;ExposeHeaders\u0026#34;: [ \u0026#34;x-amz-server-side-encryption\u0026#34;, \u0026#34;x-amz-request-id\u0026#34;, \u0026#34;x-amz-id-2\u0026#34; ], \u0026#34;MaxAgeSeconds\u0026#34;: 3000 } ] ECR Lifecycle Policy { \u0026#34;rules\u0026#34;: [ { \u0026#34;rulePriority\u0026#34;: 1, \u0026#34;description\u0026#34;: \u0026#34;Keep only the last 100 images\u0026#34;, \u0026#34;selection\u0026#34;: { \u0026#34;tagStatus\u0026#34;: \u0026#34;any\u0026#34;, \u0026#34;countType\u0026#34;: \u0026#34;imageCountMoreThan\u0026#34;, \u0026#34;countNumber\u0026#34;: 100 }, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;expire\u0026#34; } } ] } ECR Lifecycle Policy1 { \u0026#34;rules\u0026#34;: [ { \u0026#34;rulePriority\u0026#34;: 1, \u0026#34;description\u0026#34;: \u0026#34;Remove images with certain tag\u0026#34;, \u0026#34;selection\u0026#34;: { \u0026#34;tagStatus\u0026#34;: \u0026#34;tagged\u0026#34;, \u0026#34;tagPrefixList\u0026#34;: [\u0026#34;tag1\u0026#34;, \u0026#34;tag2\u0026#34;], \u0026#34;countType\u0026#34;: \u0026#34;imageCountMoreThan\u0026#34;, \u0026#34;countNumber\u0026#34;: 0 }, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;expire\u0026#34; } } ] } ECR Lifecycle Policy2 { \u0026#34;rules\u0026#34;: [ { \u0026#34;rulePriority\u0026#34;: 1, \u0026#34;description\u0026#34;: \u0026#34;Remove untagged images older than 14 days\u0026#34;, \u0026#34;selection\u0026#34;: { \u0026#34;tagStatus\u0026#34;: \u0026#34;untagged\u0026#34;, \u0026#34;countType\u0026#34;: \u0026#34;sinceImagePushed\u0026#34;, \u0026#34;countUnit\u0026#34;: \u0026#34;days\u0026#34;, \u0026#34;countNumber\u0026#34;: 14 }, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;expire\u0026#34; } } ] } ","tags":null,"title":"AWS Configure"},{"categories":null,"contents":" tf Provider provider.tf EC2 ec2.tf initial.bash Elastic IP elasticip.tf MQ mq.tf RDS rds.tf Security Group sg.tf VPC vpc.tf WAF waf.tf ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/aws/terraform/","summary":" tf Provider provider.tf EC2 ec2.tf initial.bash Elastic IP elasticip.tf MQ mq.tf RDS rds.tf Security Group sg.tf VPC vpc.tf WAF waf.tf ","tags":null,"title":"AWS Terraform"},{"categories":null,"contents":" Setting CloudFlare Worker for CORS addEventListener(\u0026#34;fetch\u0026#34;, (event) =\u0026gt; { event.respondWith(handleRequest(event.request)); }); async function handleRequest(request) { let response = await fetch(request); response = new Response(response.body, response); response.headers.set( \u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;frontend-h5.shyc883.com\u0026#34; ); response.headers.set(\u0026#34;Access-Control-Allow-Methods\u0026#34;, \u0026#34;GET, OPTIONS, POST\u0026#34;); response.headers.set( \u0026#34;Access-Control-Allow-Headers\u0026#34;, \u0026#34;Content-Type, Authorization\u0026#34; ); response.headers.set(\u0026#34;Access-Control-Allow-Credentials\u0026#34;, true); return response; } Terraform_create_record terraform { required_providers { cloudflare = { source = \u0026#34;cloudflare/cloudflare\u0026#34; version = \u0026#34;~\u0026gt; 2.0\u0026#34; } } } provider \u0026#34;cloudflare\u0026#34; { email = \u0026#34;cloudflare@gmail.com\u0026#34; api_key = \u0026#34;1488ed0d2082ed36c010b773431fd9dcacde1\u0026#34; account_id = \u0026#34;06ae012a1ba907df24a220cd14a4fa8b\u0026#34; } resource \u0026#34;cloudflare_record\u0026#34; \u0026#34;gitlab\u0026#34; { zone_id = \u0026#34;92c6d5010fbacab27d464f4d79c11fce\u0026#34; name = \u0026#34;gitlab\u0026#34; value = \u0026#34;192.123.168.234\u0026#34; type = \u0026#34;A\u0026#34; ttl = 300 proxied = true } Terraform_create_page_rule # Add a page rule to the domain resource \u0026#34;cloudflare_page_rule\u0026#34; \u0026#34;page_rule_png\u0026#34; { zone_id = \u0026#34;92c6d5010fbacab27d464f4d79c11fce\u0026#34; target = \u0026#34;www.example.com/*.png*\u0026#34; status = \u0026#34;active\u0026#34; actions { always_use_https = \u0026#34;true\u0026#34; browser_cache_ttl = 86400 cache_level = \u0026#34;cache_everything\u0026#34; # edge_cache_ttl = 86400 cache_key_fields { cookie {} header {} host {} query_string { ignore = true } user {} } # cache_ttl_by_status { # codes = \u0026#34;200-299\u0026#34; # ttl = 300 # } # cache_ttl_by_status { # codes = \u0026#34;300-399\u0026#34; # ttl = 60 # } # cache_ttl_by_status { # codes = \u0026#34;400-403\u0026#34; # ttl = -1 # } # cache_ttl_by_status { # codes = \u0026#34;404\u0026#34; # ttl = 30 # } # cache_ttl_by_status { # codes = \u0026#34;405-499\u0026#34; # ttl = -1 # } # cache_ttl_by_status { # codes = \u0026#34;500-599\u0026#34; # ttl = 0 # } # } } # resource \u0026#34;cloudflare_page_rule\u0026#34; \u0026#34;rules\u0026#34; { # count = \u0026#34;${length(keys(\u0026#34;${var.targets}\u0026#34;))}\u0026#34; # lifecycle { # create_before_destroy = true # } # zone_id = \u0026#34;92c6d5010fbacab27d464f4d79c11fce\u0026#34; # target = \u0026#34;${var.targets[element(keys(var.targets),count.index)]}\u0026#34; # actions { # always_use_https = \u0026#34;true\u0026#34; # cache_level = \u0026#34;cache_everything\u0026#34; # } # priority = \u0026#34;${count.index + 1}\u0026#34; # } Terraform_create_rate_limit_rule # Create rate limit rule resource \u0026#34;cloudflare_rate_limit\u0026#34; \u0026#34;wss_rate_limit\u0026#34; { zone_id = \u0026#34;92c6d5010fbacab27d464f4d79c11fce\u0026#34; threshold = 50 period = 60 match { request { url_pattern = \u0026#34;*wss*/*\u0026#34; } } action { mode = \u0026#34;ban\u0026#34; timeout = 3600 } correlate { by = \u0026#34;nat\u0026#34; } } resource \u0026#34;cloudflare_rate_limit\u0026#34; \u0026#34;frontend_rate_limit\u0026#34; { zone_id = \u0026#34;92c6d5010fbacab27d464f4d79c11fce\u0026#34; threshold = 50 period = 10 match { request { url_pattern = \u0026#34;*h5*/*\u0026#34; } } action { mode = \u0026#34;ban\u0026#34; timeout = 3600 } correlate { by = \u0026#34;nat\u0026#34; } } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/docs/cloudflare/","summary":"Setting CloudFlare Worker for CORS addEventListener(\u0026#34;fetch\u0026#34;, (event) =\u0026gt; { event.respondWith(handleRequest(event.request)); }); async function handleRequest(request) { let response = await fetch(request); response = new Response(response.body, response); response.headers.set( \u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;frontend-h5.shyc883.com\u0026#34; ); response.headers.set(\u0026#34;Access-Control-Allow-Methods\u0026#34;, \u0026#34;GET, OPTIONS, POST\u0026#34;); response.headers.set( \u0026#34;Access-Control-Allow-Headers\u0026#34;, \u0026#34;Content-Type, Authorization\u0026#34; ); response.headers.set(\u0026#34;Access-Control-Allow-Credentials\u0026#34;, true); return response; } Terraform_create_record terraform { required_providers { cloudflare = { source = \u0026#34;cloudflare/cloudflare\u0026#34; version = \u0026#34;~\u0026gt; 2.0\u0026#34; } } } provider \u0026#34;cloudflare\u0026#34; { email = \u0026#34;cloudflare@gmail.com\u0026#34; api_key = \u0026#34;1488ed0d2082ed36c010b773431fd9dcacde1\u0026#34; account_id = \u0026#34;06ae012a1ba907df24a220cd14a4fa8b\u0026#34; } resource \u0026#34;cloudflare_record\u0026#34; \u0026#34;gitlab\u0026#34; { zone_id = \u0026#34;92c6d5010fbacab27d464f4d79c11fce\u0026#34; name = \u0026#34;gitlab\u0026#34; value = \u0026#34;192.","tags":null,"title":"Cloudflare docs"},{"categories":null,"contents":" ab ab -n 20 -c 20 -k https://default.hddv1.com/error certbot # Install sudo apt install certbot python3-certbot-nginx python3-certbot-dns-route53 # 1. Generating Wildcard Certificates sudo certbot certonly --manual --preferred-challenges=dns --server https://acme-v02.api.letsencrypt.org/directory --agree-tos -d *.example.com ### add txt record then press enter to continue # 2. Generating Wildcard Certificates sudo certbot certonly -d example.com -d *.example.com --dns-route53 --agree-tos --server https://acme-v02.api.letsencrypt.org/directory # Automating Renewal 0 0 * * 1 /usr/bin/certbot certonly --dns-route53 -d *.example.com --quiet --post-hook \u0026#34;systemctl reload nginx\u0026#34; cutycapt # Capture website page as picture xvfb-run --server-args=\u0026#34;-screen 0, 1024x768x24\u0026#34; cutycapt --url=https://www.google.com --out=\u0026#34;/tmp/google.png\u0026#34; dnscontrol creds.json command dnscontrol get-zones --format=js --out=example.com.js r53 ROUTE53 example.com dnscontrol get-zones --format=js --out=example.com.js cloudflare CLOUDFLAREAPI example.com k6 k6.js command k6 run k6.js hey hey -n 200000 -c 500 -h2 -z 30s https://a8-wss.hddv1.com/test openfortivpn # https://github.com/adrienverge/openfortivpn sudo openfortivpn ip:port --username=ricky --pppd-use-peerdns=1 openssl # 自簽名證書，要把 ca.p7b 匯入 certmgr.msc 的受信任的根憑證授權單位，Chrome 才吃的到。 openssl crl2pkcs7 -nocrl -certfile ca.crt -out ca.p7b prlimit # 更改 Max_open_files 遇到參數錯誤，原因為 CentOS6 與 CentOS7 指令不同 # CentOS6 for i in $(ps -ef | grep \u0026#39;publish/server/game_server\u0026#39; | egrep -v \u0026#39;grep|startall\u0026#39; | awk \u0026#39;{print $2}\u0026#39;); do echo -n \u0026#34;Max open files=1024000:1024000\u0026#34; \u0026gt; /proc/$i/limits; done # CentOS7 for i in $(ps -ef | grep gateway | grep -v grep | awk \u0026#39;{print $2}\u0026#39;); do prlimit --pid $i --nofile=1024000:1024000 ; done siege siege --time=3s --concurrent=30000 https://a8-h5.hddv1.com/index.html tr # cat krypton2 YRIRY GJB CNFFJBEQ EBGGRA # cat krypton2 | tr a-zA-Z n-za-mN-ZA-M LEVEL TWO PASSWORD ROTTEN vegeta #!/usr/bin/env bash attack() { echo \u0026#34;GET ${1}\u0026#34; | vegeta attack -duration=100s -header=\u0026#34;User-Agent: baidu\u0026#34; -header=\u0026#34;X-Forwarded-For: 47.0.0.1\u0026#34; -rate=500 -timeout=1s | vegeta encode | jaggr @count=rps \\ hist\\[100,200,300,400,500\\]:code \\ p25,p50,p95:latency \\ sum:bytes_in \\ sum:bytes_out | jplot rps+code.hist.100+code.hist.200+code.hist.300+code.hist.400+code.hist.500 \\ latency.p95+latency.p50+latency.p25 \\ bytes_in.sum+bytes_out.sum } if [[ -n ${1} ]]; then attack ${1} fi ## -header=\u0026#34;Connection: Upgrade\u0026#34; -header=\u0026#34;Upgrade: websocket\u0026#34; wrk wrk -t10 -c1000 -d30s -H \u0026#34;User-Agent: baidu\u0026#34; \u0026#34;https://default.hddv1.com/error\u0026#34; Vagrant with hyper-v provider Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All Common # Find out processes swap usage command for file in /proc/*/status ; do awk \u0026#39;/VmSwap|Name/{printf $2 \u0026#34; \u0026#34; $3}END{ print \u0026#34;\u0026#34;}\u0026#39; $file; done | sort -k 2 -n -r | less Gitbook Hide gitbook sidebar default.\nraw_path=$(pwd) npm install -g gitbook-cli gitbook install cd ~/.gitbook/versions/3.2.3/node_modules/gitbook-plugin-theme-default sed -i \u0026#34;25i\\ \\ \\ \\ gitbook.storage.set(\u0026#39;sidebar\u0026#39;, false);\u0026#34; src/js/theme/sidebar.js npm install -g browserify uglify-js less less-plugin-clean-css npm install src/build.sh Install - autocorrect A linter and formatter for help you improve copywriting, to correct spaces, words, punctuations between CJK (Chinese, Japanese, Korean). Github\nwget https://github.com/huacnlee/autocorrect/releases/download/v1.7.4/autocorrect-darwin-amd64.tar.gz - bpf BCC - Tools for BPF-based Linux IO analysis, networking, monitoring, and more Kernel should higher than 4.1 Install from source is better\n# `/usr/share/bcc/` # https://github.com/iovisor/bcc # https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md#1-kernel-source-directory # https://github.com/iovisor/bpftrace yum install bcc-tools - flamegraph Stack trace visualizer\n# https://github.com/brendangregg/FlameGraph brew install flamegraph - git-split-diffs GitHub style split diffs in your terminal\nnpm install -g git-split-diffs - glci Test your Gitlab CI Pipelines changes locally using Docker. blog\nyarn global add glci - openresty wget https://openresty.org/package/centos/openresty.repo -O /etc/yum.repos.d/openresty.repo yum install -y openresty openresty-resty - perf Performance monitoring for the Linux kernel\n# https://github.com/brendangregg/Misc/blob/master/perf_events/perf.md # http://www.brendangregg.com/perf.html yum install perf - pptx2md A pptx to markdown converter\npip3 install pptx2md - sockperf Network Benchmarking Utility\n# https://github.com/Mellanox/sockperf yum install sockperf - upx UPX - the Ultimate Packer for eXecutables\nbrew install upx - wrk Modern HTTP benchmarking tool\nbrew install wrk LVM # 確認 resize 在哪個 disk lsblk # 確認 `/dev/sde` 是否為該新增 disk 路徑 pvresize /dev/sde # vgdisplay [vg 編號] # 查 free PE / Size 的編號 vgdisplay vg3 # 要升級的 lvm 硬碟路徑 lvdisplay # lvresize -l +[free 的編號] 升級的 lvm 硬碟路徑 lvresize -l +38400 /dev/vg3/disklvm4 # resize xfs_growfs /dev/vg3/disklvm4 # 檢查擴充是否成功 df -h Migration zabbix mysqldump -uroot --opt zabbix \u0026gt; zabbix.sql rsync -az zabbix.sql newserver:/root mysql -uroot zabbix \u0026lt; zabbix.sql Re-create /dev/null rm -f /dev/null mknod /dev/null c 1 3 Script ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/common/","summary":"ab ab -n 20 -c 20 -k https://default.hddv1.com/error certbot # Install sudo apt install certbot python3-certbot-nginx python3-certbot-dns-route53 # 1. Generating Wildcard Certificates sudo certbot certonly --manual --preferred-challenges=dns --server https://acme-v02.api.letsencrypt.org/directory --agree-tos -d *.example.com ### add txt record then press enter to continue # 2. Generating Wildcard Certificates sudo certbot certonly -d example.com -d *.example.com --dns-route53 --agree-tos --server https://acme-v02.api.letsencrypt.org/directory # Automating Renewal 0 0 * * 1 /usr/bin/certbot certonly --dns-route53 -d *.","tags":null,"title":"Common Command"},{"categories":null,"contents":" Build with secret Dockerfile # syntax = docker/dockerfile:1.6 FROM golang:1.21.1-alpine3.18 RUN --mount=type=secret,id=mysecret,target=/root/.ssh/id_rsa git clone git@gitlab.com:ricky/repo.git Command export DOCKER_BUILDKIT=1 docker build --secret id=mysecret,src=id_rsa -t image . Compose # Force pull image docker-compose up -d --pull always Create buildx instance # create buildx instance docker buildx create --name builder --bootstrap --driver docker-container # install emulators docker run --privileged --rm tonistiigi/binfmt --install all Create Network docker network create -d bridge --subnet 172.100.0.0/24 --gateway 172.100.0.1 backend_dev Multiple build-arg docker build . -f ./scripts/Dockerfile \\ --build-arg Date=$(date) \\ --build-arg Tag=$(git rev-list -n 1 --tags) \\ --build-arg Commit=$(git describe --tags --abbrev=0) \\ -t ops-cli Multiple platform # create and use buildx instance docker buildx create --use --name builder # build multiple platform docker buildx build --push --platform linux/arm64,linux/amd64 -t zeyanlin/ops-cli . Run container in different platform finch run -it --rm --platform=linux/arm64 zeyanlin/ops-cli /bin/sh ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/docker/","summary":"Build with secret Dockerfile # syntax = docker/dockerfile:1.6 FROM golang:1.21.1-alpine3.18 RUN --mount=type=secret,id=mysecret,target=/root/.ssh/id_rsa git clone git@gitlab.com:ricky/repo.git Command export DOCKER_BUILDKIT=1 docker build --secret id=mysecret,src=id_rsa -t image . Compose # Force pull image docker-compose up -d --pull always Create buildx instance # create buildx instance docker buildx create --name builder --bootstrap --driver docker-container # install emulators docker run --privileged --rm tonistiigi/binfmt --install all Create Network docker network create -d bridge --subnet 172.100.0.0/24 --gateway 172.","tags":null,"title":"Docker Command"},{"categories":null,"contents":" docker-compose cAdvisor docker-compose.yaml prometheus.yaml Elasticsearch docker-compose.yaml local dev docker-compose.yaml NodeJS docker-compose.yaml rstudio docker-compose.yaml rsyncd docker-compose.yaml rsyncd.conf rsyncd.secrets rsync -auz --password-file=/tmp/pass dist user@hostip::myshare Dockerfile awscli Dockerfile buildx Dockerfile docker buildx build --push --platform linux/arm64,linux/amd64 -t zeyanlin/app . dind Dockerfile golang Dockerfile docker build --secret id=mysecret,src=id_rsa -t app . rstudio Dockerfile pkg.txt supervisord Dockerfile supervisord.conf service with supervisord Dockerfile ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/docs/docker/","summary":" docker-compose cAdvisor docker-compose.yaml prometheus.yaml Elasticsearch docker-compose.yaml local dev docker-compose.yaml NodeJS docker-compose.yaml rstudio docker-compose.yaml rsyncd docker-compose.yaml rsyncd.conf rsyncd.secrets rsync -auz --password-file=/tmp/pass dist user@hostip::myshare Dockerfile awscli Dockerfile buildx Dockerfile docker buildx build --push --platform linux/arm64,linux/amd64 -t zeyanlin/app . dind Dockerfile golang Dockerfile docker build --secret id=mysecret,src=id_rsa -t app . rstudio Dockerfile pkg.txt supervisord Dockerfile supervisord.conf service with supervisord Dockerfile ","tags":null,"title":"Docker docs"},{"categories":null,"contents":" File create time 1. Find Inode $ stat dns.yaml File: dns.yaml Size: 1003 Blocks: 8 IO Block: 4096 regular file Device: ca01h/51713d Inode: 3595636 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 1000/ ubuntu) Gid: ( 1000/ ubuntu) Access: 2022-05-03 12:59:59.996755279 +0800 Modify: 2021-12-10 18:27:54.157585209 +0800 Change: 2022-01-07 14:57:58.619727878 +0800 Birth: - or\n$ ls -i dns.yaml 3585173 dns.yaml 2. Find Filesystem $ df dns.yaml Filesystem 1K-blocks Used Available Use% Mounted on /dev/root 101583780 25703988 75863408 26% / 3. Get Create Time $ sudo debugfs -R \u0026#39;stat \u0026lt;3595636\u0026gt;\u0026#39; /dev/root Inode: 3595636 Type: regular Mode: 0644 Flags: 0x80000 Generation: 449657737 Version: 0x00000000:00000001 User: 1000 Group: 1000 Project: 0 Size: 1003 File ACL: 0 Links: 1 Blockcount: 8 Fragment: Address: 0 Number: 0 Size: 0 ctime: 0x61d7e476:93c13018 -- Fri Jan 7 14:57:58 2022 atime: 0x6270b6cf:eda51d3c -- Tue May 3 12:59:59 2022 mtime: 0x61b32baa:25923ce4 -- Fri Dec 10 18:27:54 2021 crtime: 0x61b32baa:25923ce4 -- Fri Dec 10 18:27:54 2021 Size of extra inode fields: 32 Inode checksum: 0x5b176bb2 EXTENTS: (0):2665902 Display Ubuntu\u0026#39;s Message of the Day sudo chmod +x /etc/update-motd.d/* List domains sed \u0026#39;s/ //g\u0026#39; domains-info.md | awk -F \u0026#39;|\u0026#39; \u0026#39;{if($3 ~ /.*\\.com/)print $3}\u0026#39; | sort | uniq ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/file/","summary":"File create time 1. Find Inode $ stat dns.yaml File: dns.yaml Size: 1003 Blocks: 8 IO Block: 4096 regular file Device: ca01h/51713d Inode: 3595636 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 1000/ ubuntu) Gid: ( 1000/ ubuntu) Access: 2022-05-03 12:59:59.996755279 +0800 Modify: 2021-12-10 18:27:54.157585209 +0800 Change: 2022-01-07 14:57:58.619727878 +0800 Birth: - or\n$ ls -i dns.yaml 3585173 dns.yaml 2. Find Filesystem $ df dns.yaml Filesystem 1K-blocks Used Available Use% Mounted on /dev/root 101583780 25703988 75863408 26% / 3.","tags":null,"title":"File Related Command"},{"categories":null,"contents":" monitoring # list gcloud alpha monitoring policies list --project=\u0026#34;project-prod-a\u0026#34; \u0026gt;project-prod-a.yaml # update gcloud alpha monitoring policies update --policy-from-file=\u0026#34;project-prod-a.yaml\u0026#34; \u0026#34;project-prod-a\u0026#34; cloud storage # Create bucket gsutil mb -c standard -l asia-east2 gs://prod-a gsutil iam ch allUsers:objectViewer gs://prod-a # Upload files gsutil -m rsync -x \u0026#34;.svn/\u0026#34; -u -d -r srcDir gs://prod-a gsutil -m cp downloads/*.csv gs://prod-a/data/ # Create CORS file cat \u0026lt;\u0026lt; EOF \u0026gt; /data/cors.json [ { \u0026#34;origin\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;responseHeader\u0026#34;: [\u0026#34;Access-Control-Allow-Origin\u0026#34;], \u0026#34;method\u0026#34;: [\u0026#34;GET\u0026#34;,\u0026#34;HEAD\u0026#34;,\u0026#34;DELETE\u0026#34;], \u0026#34;maxAgeSeconds\u0026#34;: 3600 } ] EOF # Set CORS gsutil cors set /data/cors.json gs://prod-a/ # Check CORS gsutil cors get gs://prod-a/ # Purge CDN gcloud compute url-maps invalidate-cdn-cache balancer-client-prod-a --host ${} --path \u0026#34;/*\u0026#34; ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/gcp/command/","summary":"monitoring # list gcloud alpha monitoring policies list --project=\u0026#34;project-prod-a\u0026#34; \u0026gt;project-prod-a.yaml # update gcloud alpha monitoring policies update --policy-from-file=\u0026#34;project-prod-a.yaml\u0026#34; \u0026#34;project-prod-a\u0026#34; cloud storage # Create bucket gsutil mb -c standard -l asia-east2 gs://prod-a gsutil iam ch allUsers:objectViewer gs://prod-a # Upload files gsutil -m rsync -x \u0026#34;.svn/\u0026#34; -u -d -r srcDir gs://prod-a gsutil -m cp downloads/*.csv gs://prod-a/data/ # Create CORS file cat \u0026lt;\u0026lt; EOF \u0026gt; /data/cors.json [ { \u0026#34;origin\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;responseHeader\u0026#34;: [\u0026#34;Access-Control-Allow-Origin\u0026#34;], \u0026#34;method\u0026#34;: [\u0026#34;GET\u0026#34;,\u0026#34;HEAD\u0026#34;,\u0026#34;DELETE\u0026#34;], \u0026#34;maxAgeSeconds\u0026#34;: 3600 } ] EOF # Set CORS gsutil cors set /data/cors.","tags":null,"title":"GCP Command"},{"categories":null,"contents":" Search in git git rev-list --all | xargs git grep -F \u0026#39;\u0026#39; Count commits git rev-list --count main View a file of another branch git show dev:main.go Take a backup of untracked files git ls-files --others --exclude-standard -z | xargs -0 tar rvf backup-untracked.zip Submodule # Add submodule git submodule add -b main git@github.com:linzeyan/toha.git themes/toha # Update submodule git submodule update --init --remote # Remove submodule modulePath=\u0026#34;themes/toha\u0026#34; git submodule deinit -f ${modulePath} git rm ${modulePath} rm -rf .git/modules/${modulePath} git config --remove-section submodule.${modulePath}. rm -f .gitmodules ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/git/","summary":"Search in git git rev-list --all | xargs git grep -F \u0026#39;\u0026#39; Count commits git rev-list --count main View a file of another branch git show dev:main.go Take a backup of untracked files git ls-files --others --exclude-standard -z | xargs -0 tar rvf backup-untracked.zip Submodule # Add submodule git submodule add -b main git@github.com:linzeyan/toha.git themes/toha # Update submodule git submodule update --init --remote # Remove submodule modulePath=\u0026#34;themes/toha\u0026#34; git submodule deinit -f ${modulePath} git rm ${modulePath} rm -rf .","tags":null,"title":"Git Command"},{"categories":null,"contents":" cleanup doc\n# artifacts gitlab-rake gitlab:cleanup:orphan_job_artifact_files # expire session gitlab-rake gitlab:cleanup:sessions:active_sessions_lookup_keys # lfs gitlab-rake gitlab:cleanup:orphan_lfs_files # project gitlab-rake gitlab:cleanup:project_uploads gitlab-rake gitlab:cleanup:remote_upload_files # registry gitlab-ctl registry-garbage-collect gitlab-ctl registry-garbage-collect -m migration 1. Copy Old Crontab、Old /etc/gitlab、update-ca-trust 2. Version should be same 3. Copy newest backup file 4. Stop Services gitlab-ctl stop unicorn gitlab-ctl stop puma gitlab-ctl stop sidekiq gitlab-ctl status 5. Restore File must put in /var/opt/gitlab/backup\nchown git:git backupfile gitlab-backup restore BACKUP=11493107454_2018_04_25_10.6.4-ce 6. Check gitlab-ctl reconfigure gitlab-ctl restart gitlab-rake gitlab:check SANITIZE=true 7. Unlock gitlab-runner at Admin Area 8. Pages: Add https settings in gitlab.rb, Admin Area -\u0026gt; Applications -\u0026gt; Destroy old System OAuth, and remove secret in gitlab-secret.json. gitlab-ctl reconfigure ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/gitlab/","summary":"cleanup doc\n# artifacts gitlab-rake gitlab:cleanup:orphan_job_artifact_files # expire session gitlab-rake gitlab:cleanup:sessions:active_sessions_lookup_keys # lfs gitlab-rake gitlab:cleanup:orphan_lfs_files # project gitlab-rake gitlab:cleanup:project_uploads gitlab-rake gitlab:cleanup:remote_upload_files # registry gitlab-ctl registry-garbage-collect gitlab-ctl registry-garbage-collect -m migration 1. Copy Old Crontab、Old /etc/gitlab、update-ca-trust 2. Version should be same 3. Copy newest backup file 4. Stop Services gitlab-ctl stop unicorn gitlab-ctl stop puma gitlab-ctl stop sidekiq gitlab-ctl status 5. Restore File must put in /var/opt/gitlab/backup\nchown git:git backupfile gitlab-backup restore BACKUP=11493107454_2018_04_25_10.","tags":null,"title":"Gitlab Command"},{"categories":null,"contents":" add member by project Admin Area -\u0026gt; Settings -\u0026gt; General -\u0026gt; LDAP settings -\u0026gt; Lock memberships to LDAP synchronization -\u0026gt; Cancel backup cronjob # Backup Gitlab configs 1 0 * * * /usr/bin/tar -zcf /var/opt/gitlab/backups/`date +%Y_%m_%d`_gitlab_config.tar.gz /etc/gitlab \u0026amp;\u0026gt; /tmp/backup.log # Backup Gitlab data 1 1 * * * /usr/bin/gitlab-backup create STRATEGY=copy BACKUP=`date +%Y_%m_%d` \u0026amp;\u0026gt;\u0026gt; /tmp/backup.log # Rotate 0 2 * * * /usr/bin/rm -f `find /data/backups/ -name \u0026#34;*.tar*\u0026#34; -mtime +15` gitlab-ci.yml template gitbook gitlab-ci.yml gitbook.yml golang gitlab-ci.yml hexo gitlab-ci.yml Static resources gitlab-ci.yml template gitlab-ci.yml config gitlab-runner gitlab-runner.toml issue console output while install [execute] psql: could not connect to server: Connection refused Is the server running locally and accepting connections on Unix domain socket \u0026#34;/var/opt/gitlab/postgresql/.s.PGSQL.5432\u0026#34;? solve # stop service sudo gitlab-ctl stop sudo systemctl stop gitlab-runsvdir.service # check if there are any postgres processes; shouldn\u0026#39;t be ps aux | grep postgre # remove process pid sudo rm /var/opt/gitlab/postgresql/data/postmaster.pid # start service sudo systemctl start gitlab-runsvdir.service sudo gitlab-ctl reconfigure issue1 解決 Gitlab Pages 限制訪問權限後的 redirect invalid url。 Remove \u0026ldquo;gitlab_pages\u0026rdquo; block from /etc/gitlab/gitlab-secrets.json gitlab-ctl reconfigure issue2 console output # Gitlab Container Registry Error response from daemon: Get https://registry.knowhow.fun/v2/: x509: certificate has expired or is not yet valid /etc/gitlab/gitlab.rb solve yum install ca-certificates cd /etc/gitlab openssl genrsa -out ca.key 4096 openssl req -new -x509 -days 3650 -key ca.key -out ca.crt openssl genrsa -out server.key 4096 openssl req -new -key server.key -out server.csr openssl x509 -req -days 3650 -in server.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out server.crt cp server.crt /etc/pki/ca-trust/source/anchors/ cp ca.crt /etc/pki/ca-trust/source/anchors/ update-ca-trust issue3 console output # Gitlab Container Registry received unexpected HTTP status: 500 Internal Server Error solve /etc/gitlab/gitlab.rb\ngitlab_rails[\u0026#39;ldap_servers\u0026#39;] = { \u0026#39;main\u0026#39; =\u0026gt; { \u0026#39;encryption\u0026#39; =\u0026gt; \u0026#39;plain\u0026#39;, } } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/docs/gitlab/","summary":"add member by project Admin Area -\u0026gt; Settings -\u0026gt; General -\u0026gt; LDAP settings -\u0026gt; Lock memberships to LDAP synchronization -\u0026gt; Cancel backup cronjob # Backup Gitlab configs 1 0 * * * /usr/bin/tar -zcf /var/opt/gitlab/backups/`date +%Y_%m_%d`_gitlab_config.tar.gz /etc/gitlab \u0026amp;\u0026gt; /tmp/backup.log # Backup Gitlab data 1 1 * * * /usr/bin/gitlab-backup create STRATEGY=copy BACKUP=`date +%Y_%m_%d` \u0026amp;\u0026gt;\u0026gt; /tmp/backup.log # Rotate 0 2 * * * /usr/bin/rm -f `find /data/backups/ -name \u0026#34;*.tar*\u0026#34; -mtime +15` gitlab-ci.","tags":null,"title":"Gitlab docs"},{"categories":null,"contents":" tools httpstat It\u0026rsquo;s like curl -v, with colours. go get github.com/davecheney/httpstat jsonnet This an implementation of Jsonnet in pure Go go get github.com/google/go-jsonnet/cmd/jsonnet gosec Golang security checker go get -u github.com/securego/gosec/cmd/gosec vegeta HTTP load testing tool and library go get -u github.com/tsenart/vegeta dasel Select, put and delete data from JSON, TOML, YAML, XML and CSV files with a single tool. Supports conversion between formats and can be used as a Go package. brew install dasel go install github.com/tomwright/dasel/v2/cmd/dasel@master hey HTTP load generator, ApacheBench (ab) replacement, formerly known as rakyll/boom brew install hey slides Terminal based presentation tool brew install slides go install github.com/maaslalani/slides@latest gokart A static analysis tool for securing Go code go install github.com/praetorian-inc/gokart@latest structslop structslop is a static analyzer for Go that recommends struct field rearrangements to provide for maximum space/allocation efficiency. go install -v github.com/orijtech/structslop/cmd/structslop@v0.0.8 go get github.com/orijtech/structslop/cmd/structslop dive A tool for exploring each layer in a docker image brew install dive go get github.com/wagoodman/dive sttr cross-platform, cli app to perform various operations on string go install github.com/abhimanyu003/sttr@latest gentool Gen Tool is a single binary without dependencies can be used to generate structs from database go install gorm.io/gen/tools/gentool@latest ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/tools/","summary":"tools httpstat It\u0026rsquo;s like curl -v, with colours. go get github.com/davecheney/httpstat jsonnet This an implementation of Jsonnet in pure Go go get github.com/google/go-jsonnet/cmd/jsonnet gosec Golang security checker go get -u github.com/securego/gosec/cmd/gosec vegeta HTTP load testing tool and library go get -u github.com/tsenart/vegeta dasel Select, put and delete data from JSON, TOML, YAML, XML and CSV files with a single tool. Supports conversion between formats and can be used as a Go package.","tags":null,"title":"Go Tools"},{"categories":null,"contents":" Install brew install gnupg Generate gpg --full-generate-key gpg --list-secret-keys Generate Problem $ gpg --full-generate-key gpg: Sorry, no terminal at all requested - can\u0026#39;t get input Comment out no-tty in ~/.gnupg/gpg.conf\nAdd to git gpg --armor --export 51ADF7101CA64B2508AE29EEC279555531A1DD62 Set .gitconfig git config user.email zeyanlin@outlook.com git config user.name Ricky git config user.signingkey 51ADF7101CA64B2508AE29EEC279555531A1DD62 git config commit.gpgsign true Delete key gpg --delete-secret-keys 51ADF7101CA64B2508AE29EEC279555531A1DD62 Backup key # https://www.jwillikers.com/backup-and-restore-a-gpg-key gpg --list-secret-keys --keyid-format LONG # Export key as a file, replace email-address and Enter the private key’s passphrase gpg -o private.gpg --export-options backup --export-secret-keys rickylin@cloud-miner.net # Restore key and enter the private key’s passphrase gpg --import-options restore --import private.gpg If GPG not work echo \u0026#39;export GPG_TTY=$(tty)\u0026#39; \u0026gt;\u0026gt; ~/.zshrc gpgconf –kill gpg-agent exec $SHELL Encrypt file # Encrypt file gpg --symmetric --cipher-algo aes256 archive_file.tar # Decrypt file gpg --output archive_file.tar --decrypt archive_file.tar.gpg ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/gpg/","summary":"Install brew install gnupg Generate gpg --full-generate-key gpg --list-secret-keys Generate Problem $ gpg --full-generate-key gpg: Sorry, no terminal at all requested - can\u0026#39;t get input Comment out no-tty in ~/.gnupg/gpg.conf\nAdd to git gpg --armor --export 51ADF7101CA64B2508AE29EEC279555531A1DD62 Set .gitconfig git config user.email zeyanlin@outlook.com git config user.name Ricky git config user.signingkey 51ADF7101CA64B2508AE29EEC279555531A1DD62 git config commit.gpgsign true Delete key gpg --delete-secret-keys 51ADF7101CA64B2508AE29EEC279555531A1DD62 Backup key # https://www.jwillikers.com/backup-and-restore-a-gpg-key gpg --list-secret-keys --keyid-format LONG # Export key as a file, replace email-address and Enter the private key’s passphrase gpg -o private.","tags":null,"title":"GPG Command"},{"categories":null,"contents":" cert-manager cert-manager Route53 IAM Role Cert Manager Resource Cert Generate Resource Cert Ingress Resource # install the cert-manager CustomResourceDefinition resources kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.1/cert-manager.crds.yaml # Add the Jetstack Helm repository helm repo add jetstack https://charts.jetstack.io helm repo update # install the cert-manager helm chart helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.13.1 \\ --set installCRDs=true --set prometheus.enabled=false \\ --set webhook.timeoutSeconds=4 # uninstalling helm delete my-release kubectl delete -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.1/cert-manager.crds.yaml # create clusterissuer kubectl apply -f cert-manager-resource.yaml # generate certificate kubectl apply -f cert-generate-resource.yaml # create ingress controller kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/cloud/deploy.yaml # create ingress kubectl apply -f cert-ingress-resource.yaml helm # install plugin helm plugin install https://github.com/chartmuseum/helm-push.git # add repo ## helm repo add --username gitlab-ci-token --password ${CI_JOB_TOKEN} ${CI_PROJECT_NAME} ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/helm/stable helm repo add go2helm https://gitlab.go2cloudten.com/api/v4/projects/29/packages/helm/stable --username ricky # push chart ## https://docs.gitlab.com/ee/user/packages/helm_repository/ helm cm-push ./proxy-0.1.0.tgz go2helm kompose kompose --file docker-compose.yml convert gitlab-runner link\ngitlab-admin-service-account.yaml apiVersion: v1 kind: ServiceAccount metadata: name: gitlab namespace: kube-system apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: gitlab-admin roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: gitlab namespace: kube-system # CA Certificate kubectl get secret $(kubectl get secret | grep default | awk \u0026#39;{print $1}\u0026#39;) -o jsonpath=\u0026#34;{[\u0026#39;data\u0026#39;][\u0026#39;ca\\.crt\u0026#39;]}\u0026#34; | base64 --decode # Service Token kubectl apply -f gitlab-admin-service-account.yaml kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep gitlab | awk \u0026#39;{print $1}\u0026#39;) # https://gitlab.com/gitlab-org/charts/gitlab-runner/blob/master/values.yaml echo | openssl s_client -CAfile ca.crt -connect gitlab.knowhow.it:443 \u0026gt; /tmp/certs/server.pem # Install gitlab-runner from gitlab helm repo add gitlab https://charts.gitlab.io kubectl create namespace gitlab kubectl --namespace gitlab create secret generic gitlab-certs --from-file=gitlab.knowhow.it.crt=/tmp/certs/server.pem --from-file=registry.knowhow.it.crt=/tmp/certs/server.pem helm install --namespace gitlab k8srunner --set gitlabUrl=https://gitlab.knowhow.it,runnerRegistrationToken=VmyYjzmU_FjqyMJNJxJK,certsSecretName=gitlab-certs,rbac.create=true,runners.privileged=true,runners.tags=k8s,runners.image=alpine:3.12,runners.locked=false gitlab/gitlab-runner k3d install.sh #!/usr/bin/env bash # Install K3D curl -s https://raw.githubusercontent.com/rancher/k3d/main/install.sh | bash k3d completion bash \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc k3d cluster create rancher -s 3 k3d kubeconfig merge # Install Helm wget https://get.helm.sh/helm-v3.4.2-linux-amd64.tar.gz # https://rancher.com/docs/rancher/v2.x/en/installation/install-rancher-on-k8s/ # Install Rancher helm repo add rancher-latest https://releases.rancher.com/server-charts/latest helm repo update kubectl create namespace rancher helm install rancher rancher-latest/rancher \\ --namespace rancher \\ --set hostname=rancher.knowhow.it \\ --set ingress.tls.source=secret \\ --set privateCA=true kubectl -n rancher create secret tls tls-rancher-ingress \\ --cert=tls.crt \\ --key=tls.key kubectl -n rancher create secret generic tls-ca \\ --from-file=cacerts.pem=./cacerts.pem kubectl -n rancher rollout status deploy/rancher kind kind.yaml #kind: Cluster #apiVersion: kind.sigs.k8s.io/v1alpha3 #nodes: # - role: control-plane # - role: worker # - role: worker kind: Cluster apiVersion: kind.sigs.k8s.io/v1alpha3 nodes: - role: control-plane - role: control-plane - role: control-plane install.sh #!/usr/bin/env bash curl -Lo ./kind \u0026#34;https://github.com/kubernetes-sigs/kind/releases/download/v0.7.0/kind-$(uname)-amd64\u0026#34; chmod a+x ./kind sudo mv ./kind /usr/local/bin/kind rancher #!/usr/bin/env bash docker run \\ -d \\ --restart=always \\ --name rancher \\ --network=host \\ -v /etc/ssl/server.crt:/etc/rancher/ssl/cert.pem \\ -v /etc/ssl/server.key:/etc/rancher/ssl/key.pem \\ -v /etc/ssl/ca.crt:/etc/rancher/ssl/cacerts.pem \\ --privileged \\ rancher/rancher:latest skaffold #!/usr/bin/env bash # https://github.com/GoogleContainerTools/skaffold/examples/getting-started curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 \u0026amp;\u0026amp; \\ sudo install skaffold /usr/local/bin/ k8s in k8s #!/usr/bin/env bash ## Install kubernetes-in-kubernetes helm repo add kvaps https://kvaps.github.io/charts helm install kik kvaps/kubernetes --version 0.13.4 \\ --namespace kik \\ --create-namespace \\ --set persistence.storageClassName=local-path argocd #!/usr/bin/env bash nameSpace=\u0026#39;argocd\u0026#39; port=8443 ## helm ## https://github.com/argoproj/argo-helm/tree/master/charts/argo-cd helm repo add argo https://argoproj.github.io/argo-helm helm repo update helm install argocd argo/argo-cd \\ --namespace ${nameSpace} --create-namespace \\ --set server.service.type=NodePort \\ --set server.service.nodePortHttps=${port} ## kubectl # kubectl create namespace ${nameSpace} # kubectl apply -n ${nameSpace} -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml # sleep 60 # kubectl apply -f - \u0026lt;\u0026lt;SVC # apiVersion: v1 # kind: Service # metadata: # labels: # app.kubernetes.io/component: server # app.kubernetes.io/name: argocd-server # app.kubernetes.io/part-of: argocd # name: argocd-server # namespace: ${nameSpace} # spec: # type: NodePort # selector: # app.kubernetes.io/name: argocd-server # ports: # - name: https # nodePort: ${port} # port: 443 # targetPort: 8080 # SVC if ! which argocd 2\u0026gt;\u0026amp;1 \u0026gt;/dev/null; then wget https://github.com/argoproj/argo-cd/releases/download/v2.1.7/argocd-linux-amd64 chmod 755 argocd-linux-amd64 mv argocd-linux-amd64 /usr/local/bin/argocd fi sleep 120 account=\u0026#39;admin\u0026#39; password=$(kubectl -n ${nameSpace} get secret argocd-initial-admin-secret -o jsonpath=\u0026#34;{.data.password}\u0026#34; | base64 -d) echo ${account} echo ${password} ## CLI # argocd login https://192.168.185.95:6443 # argocd app create guestbook --repo https://github.com/argoproj/argocd-example-apps.git --path guestbook --dest-server https://kubernetes.default.svc --dest-namespace default delete() { kubectl delete clusterrole argocd-application-controller ; kubectl delete clusterrole argocd-server kubectl delete clusterrolebindings argocd-application-controller ; kubectl delete clusterrolebindings argocd-server } cert manager #!/usr/bin/env bash ## Install cert-manager ## https://cert-manager.io/docs/installation/ helm repo add jetstack https://charts.jetstack.io helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.7.2 \\ --set installCRDs=true \\ --set prometheus.enabled=false \\ --set webhook.timeoutSeconds=4 cilium #!/usr/bin/env bash set -eux use_cli() { curl -L --remote-name-all https://github.com/cilium/cilium-cli/releases/latest/download/cilium-darwin-amd64.tar.gz{,.sha256sum} shasum -a 256 -c cilium-darwin-amd64.tar.gz.sha256sum sudo tar xzvfC cilium-darwin-amd64.tar.gz /usr/local/bin rm cilium-darwin-amd64.tar.gz{,.sha256sum} cilium install } helm install cilium cilium/cilium --version 1.11.0 \\ --namespace kube-system ingress #!/usr/bin/env bash ingressClass=\u0026#39;nginx\u0026#39; ingressFile=\u0026#39;/tmp/ing.yaml\u0026#39; ingressIP=\u0026#39;192.168.185.109\u0026#39; ingressName=\u0026#39;proxy\u0026#39; ingressSuffix=\u0026#39;ingress-nginx\u0026#39; nameSpace=\u0026#39;ingress\u0026#39; nginxRepo=\u0026#39;ingress-nginx\u0026#39; replica=0 if [[ \u0026#34;$1\u0026#34; == \u0026#34;delete\u0026#34; ]]; then # Delete kubectl delete namespace ${nameSpace} kubectl delete IngressClass ${ingressClass} # kubectl delete ValidatingWebhookConfiguration ${ingressName}-ingress-nginx-admission exit $? fi if ! $(helm repo list | grep ${nginxRepo} \u0026gt;/dev/null); then echo \u0026#34;Install ${nginxRepo}\u0026#34; helm repo add ${nginxRepo} https://kubernetes.github.io/ingress-nginx helm repo update fi # --set controller.autoscaling.enabled=true \\ # --set controller.autoscaling.maxReplicas=9 \\ # --set controller.metrics.enabled=true \\ helm install ${ingressName} ${nginxRepo}/${ingressSuffix} \\ --namespace ${nameSpace} --create-namespace \\ --set controller.ingressClass=${ingressClass} \\ --set controller.replicaCount=${replica} \\ --set controller.service.externalTrafficPolicy=Local # --set controller.publishService.enabled=true # --set controller.defaultBackend.port=443 \\ # --set controller.hostNetwork=true \\ # --set controller.kind=DaemonSet \\ # --set controller.daemonset.useHostPorts=true \\ # --set controller.service.loadBalancerIP=${ingressIP} clusertIP=$(kubectl -n ingress get service | awk \u0026#39;NR==2{print $3}\u0026#39;) cat \u0026lt;\u0026lt;-EOF \u0026gt;${ingressFile} # apiVersion: v1 # kind: Service # metadata: # name: ${ingressName}-${ingressSuffix} # spec: # clusterIP: ${clusertIP} # externalIPs: # - ${ingressIP} # externalTrafficPolicy: Local # selector: # app: proxy-nginx-ingress # ports: # - name: https # port: 443 # targetPort: 443 # type: LoadBalancer # status: # loadBalancer: # ingress: # - ip: ${ingressIP} # \\-\\-\\- # kind: Endpoints # apiVersion: v1 # metadata: # name: ${ingressName}-${ingressSuffix} # subsets: # - addresses: # - ip: 54.238.209.164 # ports: # - name: https # port: 443 # - name: ssh # port: 22 \\-\\-\\- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress annotations: kubernetes.io/ingress.class: ${ingressClass} nginx.ingress.kubernetes.io/upstream-vhost: own.go2cloudten.com nginx.ingress.kubernetes.io/backend-protocol: \u0026#34;HTTPS\u0026#34; nginx.ingress.kubernetes.io/default-backend: ${ingressName}-${ingressSuffix}-controller nginx.ingress.kubernetes.io/http2-push-preload: \u0026#34;true\u0026#34; nginx.ingress.kubernetes.io/service-upstream: \u0026#34;true\u0026#34; # nginx.ingress.kubernetes.io/rewrite-target: / spec: # defaultBackend: # service: # name: ${ingressName}-${ingressSuffix} # port: # number: 443 rules: - host: gitlab.go2cloudten.com http: paths: - path: /* pathType: Prefix backend: service: name: ${ingressName}-${ingressSuffix} port: number: 443 # - path: /* # pathType: Prefix # backend: # service: # name: ${ingressName}-${ingressSuffix} # port: # name: ssh EOF # kubectl -n ingress apply -f ${ingressFile} krew #!/usr/bin/env bash set -x cd \u0026#34;$(mktemp -d)\u0026#34; \u0026amp;\u0026amp; OS=\u0026#34;$(uname | tr \u0026#39;[:upper:]\u0026#39; \u0026#39;[:lower:]\u0026#39;)\u0026#34; \u0026amp;\u0026amp; ARCH=\u0026#34;$(uname -m | sed -e \u0026#39;s/x86_64/amd64/\u0026#39; -e \u0026#39;s/\\(arm\\)\\(64\\)\\?.*/\\1\\2/\u0026#39; -e \u0026#39;s/aarch64$/arm64/\u0026#39;)\u0026#34; \u0026amp;\u0026amp; KREW=\u0026#34;krew-${OS}_${ARCH}\u0026#34; \u0026amp;\u0026amp; curl -fsSLO \u0026#34;https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz\u0026#34; \u0026amp;\u0026amp; tar zxvf \u0026#34;${KREW}.tar.gz\u0026#34; \u0026amp;\u0026amp; ./\u0026#34;${KREW}\u0026#34; install krew export PATH=\u0026#34;${KREW_ROOT:-$HOME/.krew}/bin:$PATH\u0026#34; kubectl krew install change-ns kubectl change-ns nginx prometheus #!/usr/bin/env bash nameSpace=\u0026#39;monitoring\u0026#39; prometheusPort=9090 grafanaPort=3000 kubeControllerManagerDefaultPort=10257 ## helm ## https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack ## 1. monitoring every namespaces and export port ## 2. export grafana port ## 3. monitoring kubeControllerManager helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack \\ --namespace \u0026#34;${nameSpace}\u0026#34; \\ --create-namespace \\ --set prometheus.prometheusSpec.podMonitorSelectorNilUsesHelmValues=false \\ --set prometheus.prometheusSpec.ruleSelectorNilUsesHelmValues=false \\ --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false \\ --set prometheus.service.type=NodePort \\ --set prometheus.service.nodePort=${prometheusPort} \\ --set grafana.service.type=NodePort \\ --set grafana.service.nodePort=${grafanaPort} \\ --set kubeControllerManager.service.port=${kubeControllerManagerDefaultPort} \\ --set kubeControllerManager.service.targetPort=${kubeControllerManagerDefaultPort} \\ --set kubeControllerManager.ServiceMonitor.https=true \\ --set kubeControllerManager.ServiceMonitor.insecureSkipVerify=true \\ --set kubeControllerManager.ServiceMonitor.serverName=localhost sleep 30 account=$(kubectl -n \u0026#34;${nameSpace}\u0026#34; get secret kube-prometheus-stack-grafana -o jsonpath=\u0026#34;{.data.admin-user}\u0026#34; | base64 -d) password=$(kubectl -n \u0026#34;${nameSpace}\u0026#34; get secret kube-prometheus-stack-grafana -o jsonpath=\u0026#34;{.data.admin-password}\u0026#34; | base64 -d) Create and use secret command kubectl -n nginx create secret docker-registry gitlab --docker-server=registry.go2cloudten.com --docker-username=ricky --docker-password=\u0026#34;token or password\u0026#34; config imagePullSecrets: - name: gitlab Run pod kubectl run -it --rm --image=registry.go2cloudten.com/it/docker/backup test --image-pull-policy=IfNotPresent -- bash ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/k8s/","summary":"cert-manager cert-manager Route53 IAM Role Cert Manager Resource Cert Generate Resource Cert Ingress Resource # install the cert-manager CustomResourceDefinition resources kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.1/cert-manager.crds.yaml # Add the Jetstack Helm repository helm repo add jetstack https://charts.jetstack.io helm repo update # install the cert-manager helm chart helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.13.1 \\ --set installCRDs=true --set prometheus.enabled=false \\ --set webhook.timeoutSeconds=4 # uninstalling helm delete my-release kubectl delete -f https://github.","tags":null,"title":"K8s Command"},{"categories":null,"contents":" docker.service ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --bip 10.255.0.1/16 --containerd=/run/containerd/containerd.sock --insecure-registry hub.srjob.co:8888 --insecure-registry registry.knowhow.fun gd.service [Unit] Description=Fetch DNS After=network.target After=mysql.service [Service] WorkingDirectory=/data/dns ExecStart=/data/dns/gd -o hourly ExecReload=/bin/kill -s HUP $MAINPID Restart=always [Install] WantedBy=multi-user.target openresty.service [Unit] Description=The OpenResty Application Platform After=syslog.target network-online.target remote-fs.target nss-lookup.target Wants=network-online.target [Service] Type=forking WorkingDirectory=/data/config/nginx PIDFile=/data/config/nginx/logs/nginx.pid ExecStartPre=/usr/bin/chown -R root:root /data/nginx ExecStartPre=/usr/bin/rm -f /data/nginx/logs/nginx.pid ExecStartPre=/usr/local/openresty/nginx/sbin/nginx -p /data/nginx -t ExecStart=/usr/local/openresty/nginx/sbin/nginx -p /data/nginx ExecReload=/bin/kill -s HUP $MAINPID ExecStop=-/sbin/start-stop-daemon --quiet --stop --retry QUIT/5 --pidfile /data/nginx/logs/nginx.pid #ExecStop=/bin/kill -s QUIT $MAINPID KillSignal=SIGQUIT TimeoutStopSec=5 KillMode=process PrivateTmp=true LimitNOFILE=1048576 [Install] WantedBy=multi-user.target pm2.service [Unit] Description=PM2 process manager Documentation=https://pm2.keymetrics.io/ After=network.target [Service] Type=forking User=root LimitNOFILE=infinity LimitNPROC=infinity LimitCORE=infinity Environment=PM2_HOME=/root/.pm2 PIDFile=/root/.pm2/pm2.pid WorkingDirectory=/game/publish ExecStart=/lib/node_modules/pm2/bin/pm2 start game_api.json manage.json ExecReload=/lib/node_modules/pm2/bin/pm2 reload all ExecStop=/lib/node_modules/pm2/bin/pm2 kill [Install] WantedBy=multi-user.target logrotate /data/gameapi/logs/*.log { create 0644 nobody root daily rotate 30 dateext missingok notifempty compress sharedscripts postrotate /bin/kill -USR1 `cat /data/gameapi/logs/nginx.pid 2\u0026gt;/dev/null` 2\u0026gt;/dev/null || true endscript } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/docs/linux/","summary":"docker.service ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --bip 10.255.0.1/16 --containerd=/run/containerd/containerd.sock --insecure-registry hub.srjob.co:8888 --insecure-registry registry.knowhow.fun gd.service [Unit] Description=Fetch DNS After=network.target After=mysql.service [Service] WorkingDirectory=/data/dns ExecStart=/data/dns/gd -o hourly ExecReload=/bin/kill -s HUP $MAINPID Restart=always [Install] WantedBy=multi-user.target openresty.service [Unit] Description=The OpenResty Application Platform After=syslog.target network-online.target remote-fs.target nss-lookup.target Wants=network-online.target [Service] Type=forking WorkingDirectory=/data/config/nginx PIDFile=/data/config/nginx/logs/nginx.pid ExecStartPre=/usr/bin/chown -R root:root /data/nginx ExecStartPre=/usr/bin/rm -f /data/nginx/logs/nginx.pid ExecStartPre=/usr/local/openresty/nginx/sbin/nginx -p /data/nginx -t ExecStart=/usr/local/openresty/nginx/sbin/nginx -p /data/nginx ExecReload=/bin/kill -s HUP $MAINPID ExecStop=-/sbin/start-stop-daemon --quiet --stop --retry QUIT/5 --pidfile /data/nginx/logs/nginx.","tags":null,"title":"Linux docs"},{"categories":null,"contents":" details 看我 你看不到我 看不到我 link flowchart LR A --o B B --x C D o--o E E \u0026lt;--\u0026gt; F F x--x G shapes graph LR id1[方框] id2(帶有圓角的方框) id3([體育場形狀]) id4[[子例程]] id5[(圓柱狀)] id6((圓形)) id7\u0026gt;非對稱形狀] id8{菱形} id9{{六角形}} id10[/平行四邊形 1/] id11[\\平行四邊形 2\\] id12[/梯形 1\\] id13[\\梯形 2/] id14(((雙圓))) subgraphs flowchart TD c1--\u0026gt;a2 subgraph one a1--\u0026gt;a2 end subgraph \u0026#34;`**two**`\u0026#34; b1--\u0026gt;b2 end subgraph three c1--\u0026gt;c2 end sequence sequenceDiagram participant Alice participant Bob Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts \u0026lt;br/\u0026gt;prevail... John--\u0026gt;Alice: Great! John-\u0026gt;Bob: How about you? Bob--\u0026gt;John: Jolly good! gantt gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2014-01-06,24h Implement parser and jison :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to mermaid :1d class classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool Class03 _-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --\u0026gt; C2 : Where am i? Class09 --_ C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 \u0026lt;--\u0026gt; C2: Cool label state stateDiagram-v2 open: Open Door closed: Closed Door locked: Locked Door open --\u0026gt; closed: Close closed --\u0026gt; locked: Lock locked --\u0026gt; closed: Unlock closed --\u0026gt; open: Open git gitGraph: options { \u0026#34;nodeSpacing\u0026#34;: 150, \u0026#34;nodeRadius\u0026#34;: 10 } end commit branch newbranch checkout newbranch commit commit checkout master commit commit merge newbranch graph LR A --- B A ---|text| B C --\u003e D C --\u003e|text| D E -.- F E -.-|text| F G -.-\u003e H G -.-\u003e|text| H I === J I ===|text| J ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/docs/mermaid/","summary":"details 看我 你看不到我 看不到我 link flowchart LR A --o B B --x C D o--o E E \u0026lt;--\u0026gt; F F x--x G shapes graph LR id1[方框] id2(帶有圓角的方框) id3([體育場形狀]) id4[[子例程]] id5[(圓柱狀)] id6((圓形)) id7\u0026gt;非對稱形狀] id8{菱形} id9{{六角形}} id10[/平行四邊形 1/] id11[\\平行四邊形 2\\] id12[/梯形 1\\] id13[\\梯形 2/] id14(((雙圓))) subgraphs flowchart TD c1--\u0026gt;a2 subgraph one a1--\u0026gt;a2 end subgraph \u0026#34;`**two**`\u0026#34; b1--\u0026gt;b2 end subgraph three c1--\u0026gt;c2 end sequence sequenceDiagram participant Alice participant Bob Alice-\u0026gt;\u0026gt;John: Hello John, how are you?","tags":null,"title":"mermaid notes"},{"categories":null,"contents":" Synology Active Backup for Bussiness backup task failed Due to IP change last week Firewall policy create NAS_to_ESXi。 虛擬機器 -\u0026gt; 任務清單 -\u0026gt; 刪除任務。 虛擬機器 -\u0026gt; VMware vSphere -\u0026gt; 管理 Hypervisor -\u0026gt; 刪除舊的 IP，新增新的 IP。 Set LACP for Synology NAS and NETGEAR switch NETGEAR Switching -\u0026gt; LAG -\u0026gt; LAG Configuration -\u0026gt; ch1 -\u0026gt; 41、42 -\u0026gt; Apply。 ch1 -\u0026gt; Description: NAS、LAG Type:LACP -\u0026gt; Apply。 Switching -\u0026gt; VLAN -\u0026gt; Port PVID Configuration -\u0026gt; g41、g42 PVID:99、VLAN Member:10-14,17-23,99,101、VLAN Tag:10-14,17-23,99,101 -\u0026gt; Apply。 Synology 控制台 -\u0026gt; 網路 -\u0026gt; 網路介面 -\u0026gt; 新增 Bond。 Set NAT in FortiGate 1. 政策\u0026amp;物件 -\u0026gt; 虛擬 IP -\u0026gt; 新增 名稱: IT-VPN 介面: wan2 對外 IP: 0.0.0.0 埠號轉發 協定: TCP 外部服務埠號: 19979 對應到埠號: 19979 2. 政策\u0026amp;物件 -\u0026gt; IPv4 政策 From zone wan2 to zone Knowhow_Vlan From any to IT-VPN Juniper SRX 320 # 查看當前軟體版本號 show system software # 查看系統啟動時間 show system uptime # 查看硬體板卡及序號 show chassis haredware # 查看硬體板卡當前狀態 show chassis environment # 查看主控板（RE）資源使用及狀態 show chassis routing-engine # 查看當前防火牆併發會話數 show security flow session summary # 查看當前防火牆具體併發會話 show security flow session # 清除當前 session clear security flow session all # 檢查全域 ALG 開啟情況 show security alg status # 查OID show snmp mib walk decimal 1.3.6.1.2.1.2.2.1.2 # 設定政策 set security policy zones from-zone to-zone # 查看路由表 show route # 查看 ARP 表 show arp # 查看系統日誌 show log messages # 查看所有介面運行狀態 show interface terse # 查看介面運行細節資訊 show interface ge-x/y/z detail # 比較修改 show | compare rollback ? show | compare rollback 1 # 查看系統 show system # 查看設定 show configuration # 動態統計介面資料包轉發資訊 monitor interface ge-x/y/z # 動態報文抓取（Tcpdump，類似 ScreenOS snoop命令） monitor traffic interface ge-x/y/z ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/docs/network/","summary":"Synology Active Backup for Bussiness backup task failed Due to IP change last week Firewall policy create NAS_to_ESXi。 虛擬機器 -\u0026gt; 任務清單 -\u0026gt; 刪除任務。 虛擬機器 -\u0026gt; VMware vSphere -\u0026gt; 管理 Hypervisor -\u0026gt; 刪除舊的 IP，新增新的 IP。 Set LACP for Synology NAS and NETGEAR switch NETGEAR Switching -\u0026gt; LAG -\u0026gt; LAG Configuration -\u0026gt; ch1 -\u0026gt; 41、42 -\u0026gt; Apply。 ch1 -\u0026gt; Description: NAS、LAG Type:LACP -\u0026gt; Apply。 Switching -\u0026gt; VLAN -\u0026gt; Port PVID Configuration -\u0026gt; g41、g42 PVID:99、VLAN Member:10-14,17-23,99,101、VLAN Tag:10-14,17-23,99,101 -\u0026gt; Apply。 Synology 控制台 -\u0026gt; 網路 -\u0026gt; 網路介面 -\u0026gt; 新增 Bond。 Set NAT in FortiGate 1.","tags":null,"title":"Network docs"},{"categories":null,"contents":" Check port status # `(echo \u0026gt;/dev/tcp/${host}/${port})` (echo \u0026gt;/dev/tcp/192.168.57.24/80) \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026#34;open\u0026#34; || echo \u0026#34;closed\u0026#34; timeout 1 bash -c \u0026#39;\u0026gt;/dev/tcp/192.168.57.24/80 \u0026amp;\u0026gt;/dev/null\u0026#39; \u0026amp;\u0026amp; echo \u0026#34;open\u0026#34; || echo \u0026#34;closed\u0026#34; timeout 1 bash -c \u0026#39;\u0026gt;/dev/tcp/192.168.57.24/80\u0026#39; \u0026amp;\u0026amp; echo \u0026#34;open\u0026#34; || echo \u0026#34;closed\u0026#34; Block subnets ip route add blackhole 192.168.0.0/24 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/network/","summary":" Check port status # `(echo \u0026gt;/dev/tcp/${host}/${port})` (echo \u0026gt;/dev/tcp/192.168.57.24/80) \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026#34;open\u0026#34; || echo \u0026#34;closed\u0026#34; timeout 1 bash -c \u0026#39;\u0026gt;/dev/tcp/192.168.57.24/80 \u0026amp;\u0026gt;/dev/null\u0026#39; \u0026amp;\u0026amp; echo \u0026#34;open\u0026#34; || echo \u0026#34;closed\u0026#34; timeout 1 bash -c \u0026#39;\u0026gt;/dev/tcp/192.168.57.24/80\u0026#39; \u0026amp;\u0026amp; echo \u0026#34;open\u0026#34; || echo \u0026#34;closed\u0026#34; Block subnets ip route add blackhole 192.168.0.0/24 ","tags":null,"title":"Network Related Command"},{"categories":null,"contents":" map # map map $remote_addr $limit_key { 35.229.201.209 \u0026#34;\u0026#34;; default $binary_remote_addr; } # wss.conf limit_req_zone $limit_key zone=websocket:10m rate=20r/s; limit_req_status 499; server { location = / { limit_req zone=websocket nodelay; limit_req_log_level warn; } } rewrite 1 # https://localhost/img/nginx.svg can access /data/nginxconfig.io/src/static/nginx.svg location /img { rewrite \u0026#39;^/img/(.*)$\u0026#39; /static/$1; } location /static { root /data/nginxconfig.io/src; index nginx.svg; } 2 # https://localhost/photo/nginx.svg can access /data/nginxconfig.io/src/static/nginx.svg location /photo { root /data/nginxconfig.io/src; try_files $uri /$uri @pic; } location @pic { rewrite \u0026#39;^/photo/(.*)$\u0026#39; /static/$1; } 3 # remove prefix path and allow proxy_pass POST location /upload/ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; root /data/nginx/html; # Remove path rewrite ^/upload/(.*) /$1 break; proxy_pass https://logo$uri$is_args$args; # Proxy_pass POST proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#39;upgrade\u0026#39;; proxy_cache_bypass $http_upgrade; #proxy_redirect https://logo/ /; } location / { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; root /data/nginx/html; index index.html index.htm; } grafana behind nginx server/ssl.conf ssl_certificate /etc/ssl/go2cloudten.com.crt; ssl_certificate_key /etc/ssl/go2cloudten.com.key; ssl_ciphers \u0026#34;EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC2:!RC4:!aNULL:!eNULL:!LOW:!IDEA:!DES:!TDES:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!EXPORT:!ANON\u0026#34;; ssl_prefer_server_ciphers on; ssl_protocols TLSv1.2 TLSv1.3; ssl_session_timeout 50m; server/proxy.conf proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; grafana.conf server { listen 443 ssl; server_name grafana-test.go2cloudten.com; server_name grafana.go2cloudten.com; include server/ssl.conf; include server/proxy.conf; access_log logs/grafana.log json; error_log logs/grafana.error.log warn; location / { proxy_pass http://grafana; proxy_connect_timeout 300; proxy_read_timeout 700; proxy_send_timeout 700; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; } } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/docs/nginx/","summary":"map # map map $remote_addr $limit_key { 35.229.201.209 \u0026#34;\u0026#34;; default $binary_remote_addr; } # wss.conf limit_req_zone $limit_key zone=websocket:10m rate=20r/s; limit_req_status 499; server { location = / { limit_req zone=websocket nodelay; limit_req_log_level warn; } } rewrite 1 # https://localhost/img/nginx.svg can access /data/nginxconfig.io/src/static/nginx.svg location /img { rewrite \u0026#39;^/img/(.*)$\u0026#39; /static/$1; } location /static { root /data/nginxconfig.io/src; index nginx.svg; } 2 # https://localhost/photo/nginx.svg can access /data/nginxconfig.io/src/static/nginx.svg location /photo { root /data/nginxconfig.io/src; try_files $uri /$uri @pic; } location @pic { rewrite \u0026#39;^/photo/(.","tags":null,"title":"Nginx docs"},{"categories":null,"contents":" texlive macOS # brew install textlive # npm i -g mermaid-filter # Render mermaid pandoc -F mermaid-filter -o readme.pdf readme.md Ubuntu # sudo apt install pandoc -y # sudo apt-get -y install texlive-latex-recommended texlive-pictures texlive-latex-extra texlive-fonts-recommended # npm i -g mermaid-filter pandoc -F mermaid-filter -o readme.pdf readme.md ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/pandoc/","summary":" texlive macOS # brew install textlive # npm i -g mermaid-filter # Render mermaid pandoc -F mermaid-filter -o readme.pdf readme.md Ubuntu # sudo apt install pandoc -y # sudo apt-get -y install texlive-latex-recommended texlive-pictures texlive-latex-extra texlive-fonts-recommended # npm i -g mermaid-filter pandoc -F mermaid-filter -o readme.pdf readme.md ","tags":null,"title":"Pandoc Command"},{"categories":null,"contents":" Install # Ubuntu22.04 sudo add-apt-repository ppa:redislabs/redis sudo apt install redis-server ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/redis/","summary":" Install # Ubuntu22.04 sudo add-apt-repository ppa:redislabs/redis sudo apt install redis-server ","tags":null,"title":"Redis Install Command"},{"categories":null,"contents":" Generate ssh key # RSA ssh-keygen -m PEM -t rsa -b 4096 -C \u0026#34;zeyanlin@outlook.com\u0026#34; # ED25519 ssh-keygen -t ed25519 -C \u0026#34;dev\u0026#34; -f ~/.ssh/ed25519 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/bash/ssh/","summary":" Generate ssh key # RSA ssh-keygen -m PEM -t rsa -b 4096 -C \u0026#34;zeyanlin@outlook.com\u0026#34; # ED25519 ssh-keygen -t ed25519 -C \u0026#34;dev\u0026#34; -f ~/.ssh/ed25519 ","tags":null,"title":"SSH Command"},{"categories":null,"contents":" Vagrantfile template docker Nginx hyperv CentOS7 Win2019 virtualbox Vagrantfile vmware Vagrantfile multi Vagrantfile others common Vagrantfile Metasploitable3 Vagrantfile ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/docs/vagrant/","summary":" Vagrantfile template docker Nginx hyperv CentOS7 Win2019 virtualbox Vagrantfile vmware Vagrantfile multi Vagrantfile others common Vagrantfile Metasploitable3 Vagrantfile ","tags":null,"title":"Vagrant docs"},{"categories":null,"contents":" send alert Use Webhook, Create Channel and Webhook in Mattermost, and put script to $(grep AlertScriptsPath /etc/zabbix/zabbix_server.conf). Create Media types in Zabbix(Administration -\u0026gt; Medai types). Add media to user(Administration -\u0026gt; Users -\u0026gt; Media). Create action(Configuration -\u0026gt; Actions -\u0026gt; Trigger actions)。 Debug(Write log in script). Media types: PROBLEM:\\nProblem started at {EVENT.TIME} on {EVENT.DATE}\\n 問題: {EVENT.NAME}\\n 主機: {HOST.NAME}\\nSeverity: {EVENT.SEVERITY}\\n 目前數值: {EVENT.OPDATA}\\n 問題 ID: {EVENT.ID}\\n{TRIGGER.URL} RECOVERY:\\nProblem has been resolved at {EVENT.RECOVERY.TIME} on {EVENT.RECOVERY.DATE}\\n 問題: {EVENT.NAME}\\n 持續時間: {EVENT.DURATION}\\n 主機: {HOST.NAME}\\nSeverity: {EVENT.SEVERITY}\\n 問題 ID: {EVENT.ID}\\n{TRIGGER.URL} zabbix server /etc/zabbix/zabbix_server.conf Zabbix Server perform high loading, and slow query. Increase ValueCacheSize solve this problem.\nLogFile=/var/log/zabbix/zabbix_server.log LogFileSize=5 PidFile=/var/run/zabbix/zabbix_server.pid SocketDir=/var/run/zabbix DBHost=localhost DBName=zabbix_db DBUser=zabbix_user DBPassword=zabbix DBSocket=/data/mysql/mysql.sock StartPollers=200 StartPreprocessors=30 StartPollersUnreachable=30 StartTrappers=100 StartDiscoverers=30 SNMPTrapperFile=/var/log/snmptrap/snmptrap.log CacheSize=4G HistoryCacheSize=2G HistoryIndexCacheSize=2G TrendCacheSize=2G ValueCacheSize=24G Timeout=30 UnavailableDelay=120 AlertScriptsPath=/usr/lib/zabbix/alertscripts ExternalScripts=/usr/lib/zabbix/externalscripts LogSlowQueries=3000 StatsAllowedIP=127.0.0.1 /etc/my.cnf [client-server] socket=/data/mysql/mysql.sock [mysqld] socket=/data/mysql/mysql.sock datadir=/data/mysql character_set_server=utf8mb4 character_set_filesystem=utf8 max_allowed_packet=32M event_scheduler=1 default_storage_engine=innodb open_files_limit=65535 local_infile=1 sysdate_is_now=1 back_log=256 ##error log format # connection interactive_timeout=28800 wait_timeout=28800 lock_wait_timeout=28800 skip_name_resolve=1 max_connections=2000 max_user_connections=1000 max_connect_errors=1000000 # table cache performance settings # table_open_cache=8192 table_definition_cache=8192 table_open_cache_instances=16 # session memory settings # read_buffer_size=131072 read_rnd_buffer_size=262144 sort_buffer_size=262144 tmp_table_size=67108864 join_buffer_size=8M thread_cache_size=256 # log settings # ###slow log ### slow_query_log=1 log_queries_not_using_indexes=0 log_slow_admin_statements=1 #log_slow_slave_statements = 1 log_throttle_queries_not_using_indexes=1 long_query_time=0.5 log_bin_trust_function_creators=1 ###binlog ### binlog_cache_size=32K max_binlog_cache_size=1G max_binlog_size=2G expire_logs_days=31 log_slave_updates=1 #binlog_format=STATEMENT binlog_format=ROW slave_compressed_protocol = 1 # innodb settings # #innodb_data_file_path=ibdata1:4G;ibdata2:4G:autoextend innodb_page_size=16384 innodb_buffer_pool_size=4G innodb_buffer_pool_instances=1 innodb_buffer_pool_load_at_startup=1 innodb_buffer_pool_dump_at_shutdown=1 innodb_lock_wait_timeout=50 innodb_io_capacity=100 innodb_io_capacity_max=200 innodb_flush_neighbors=1 innodb_file_per_table=1 innodb_log_files_in_group=3 innodb_log_file_size=2G innodb_log_buffer_size=33554432 innodb_purge_threads=2 innodb_large_prefix=1 innodb_thread_concurrency=64 innodb_print_all_deadlocks=1 innodb_strict_mode=1 innodb_sort_buffer_size=67108864 innodb_write_io_threads=4 innodb_read_io_threads=4 innodb_online_alter_log_max_size=1G innodb_open_files=60000 innodb_max_dirty_pages_pct=75 innodb_adaptive_flushing=on innodb_flush_log_at_trx_commit=1 sync_binlog =1 [mysqld_safe] log-error=/var/log/mariadb/mariadb.log # # include *.cnf from the config directory # !includedir /etc/my.cnf.d ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/docs/zabbix/","summary":"send alert Use Webhook, Create Channel and Webhook in Mattermost, and put script to $(grep AlertScriptsPath /etc/zabbix/zabbix_server.conf). Create Media types in Zabbix(Administration -\u0026gt; Medai types). Add media to user(Administration -\u0026gt; Users -\u0026gt; Media). Create action(Configuration -\u0026gt; Actions -\u0026gt; Trigger actions)。 Debug(Write log in script). Media types: PROBLEM:\\nProblem started at {EVENT.TIME} on {EVENT.DATE}\\n 問題: {EVENT.NAME}\\n 主機: {HOST.NAME}\\nSeverity: {EVENT.SEVERITY}\\n 目前數值: {EVENT.OPDATA}\\n 問題 ID: {EVENT.ID}\\n{TRIGGER.URL} RECOVERY:\\nProblem has been resolved at {EVENT.RECOVERY.TIME} on {EVENT.","tags":null,"title":"Zabbix docs"},{"categories":null,"contents":" array package main import ( \u0026#34;fmt\u0026#34; ) func main() { a := [5]int{1, 2, 3, 4, 5} t := a[3:4:4] fmt.Println(t[0]) } A. 3 B. 4 C. compilation error Answer Try it B ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/array/","summary":" array package main import ( \u0026#34;fmt\u0026#34; ) func main() { a := [5]int{1, 2, 3, 4, 5} t := a[3:4:4] fmt.Println(t[0]) } A. 3 B. 4 C. compilation error Answer Try it B ","tags":null,"title":"Array"},{"categories":null,"contents":" channel package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ch := make(chan int, 1000) go func() { for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i } }() go func() { for { a, ok := \u0026lt;-ch if !ok { fmt.Println(\u0026#34;close\u0026#34;) return } fmt.Println(\u0026#34;a: \u0026#34;, a) } }() close(ch) fmt.Println(\u0026#34;ok\u0026#34;) time.Sleep(time.Second * 100) } Answer Try it ok panic: send on closed channel channel1 package main import ( \u0026#34;fmt\u0026#34; ) func main() { c := make(chan int) close(c) val, _ := \u0026lt;-c fmt.Println(val) } Answer Try it 0 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/channel/","summary":"channel package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ch := make(chan int, 1000) go func() { for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i } }() go func() { for { a, ok := \u0026lt;-ch if !ok { fmt.Println(\u0026#34;close\u0026#34;) return } fmt.Println(\u0026#34;a: \u0026#34;, a) } }() close(ch) fmt.Println(\u0026#34;ok\u0026#34;) time.Sleep(time.Second * 100) } Answer Try it ok panic: send on closed channel channel1 package main import ( \u0026#34;fmt\u0026#34; ) func main() { c := make(chan int) close(c) val, _ := \u0026lt;-c fmt.","tags":null,"title":"Channel"},{"categories":null,"contents":" context package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; ) func f(ctx context.Context) { context.WithValue(ctx, \u0026#34;foo\u0026#34;, -6) } func main() { ctx := context.TODO() f(ctx) fmt.Println(ctx.Value(\u0026#34;foo\u0026#34;)) } A. -6 B. 0 C. \u0026lt;nil\u0026gt; D: panic Answer Try it C context1 package main import( \u0026#34;fmt\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;context\u0026#34; ) func main() { data, _ := json.Marshal(context.WithValue(context.Background(), \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;)) fmt.Println(string(data)) } Answer Try it {\"Context\":0} ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/context/","summary":" context package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; ) func f(ctx context.Context) { context.WithValue(ctx, \u0026#34;foo\u0026#34;, -6) } func main() { ctx := context.TODO() f(ctx) fmt.Println(ctx.Value(\u0026#34;foo\u0026#34;)) } A. -6 B. 0 C. \u0026lt;nil\u0026gt; D: panic Answer Try it C context1 package main import( \u0026#34;fmt\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;context\u0026#34; ) func main() { data, _ := json.Marshal(context.WithValue(context.Background(), \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;)) fmt.Println(string(data)) } Answer Try it {\"Context\":0} ","tags":null,"title":"Context"},{"categories":null,"contents":" defer package main import ( \u0026#34;fmt\u0026#34; ) func main() { defer_call() } func defer_call() { defer func() { fmt.Println(\u0026#34;1\u0026#34;) }() defer func() { fmt.Println(\u0026#34;2\u0026#34;) }() defer func() { fmt.Println(\u0026#34;3\u0026#34;) }() panic(\u0026#34;4\u0026#34;) } Answer Try it 3 2 1 panic: 4 defer1 package main import ( \u0026#34;fmt\u0026#34; ) type Person struct { age int } func main() { person := \u0026amp;Person{28} defer fmt.Println(person.age) defer func(p *Person) { fmt.Println(p.age) }(person) defer func() { fmt.Println(person.age) }() person.age = 29 } Answer Try it 29 29 28 defer2 package main import ( \u0026#34;fmt\u0026#34; ) type Person struct { age int } func main() { person := \u0026amp;Person{28} defer fmt.Println(person.age) defer func(p *Person) { fmt.Println(p.age) }(person) defer func() { fmt.Println(person.age) }() person = \u0026amp;Person{29} } Answer Try it 29 28 28 defer3 package main import ( \u0026#34;fmt\u0026#34; ) var a bool = true func main() { defer func() { fmt.Println(\u0026#34;1\u0026#34;) }() if a == true { fmt.Println(\u0026#34;2\u0026#34;) return } defer func() { fmt.Println(\u0026#34;3\u0026#34;) }() } Answer Try it 2 1 defer4 package main import \u0026#34;fmt\u0026#34; type temp struct{} func (t *temp) Add(elem int) *temp { fmt.Print(elem) return \u0026amp;temp{} } func main() { tt := \u0026amp;temp{} defer tt.Add(1).Add(2) tt.Add(3) } A. 132 B. 123 C. 312 D. 321 Answer Try it A ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/defer/","summary":"defer package main import ( \u0026#34;fmt\u0026#34; ) func main() { defer_call() } func defer_call() { defer func() { fmt.Println(\u0026#34;1\u0026#34;) }() defer func() { fmt.Println(\u0026#34;2\u0026#34;) }() defer func() { fmt.Println(\u0026#34;3\u0026#34;) }() panic(\u0026#34;4\u0026#34;) } Answer Try it 3 2 1 panic: 4 defer1 package main import ( \u0026#34;fmt\u0026#34; ) type Person struct { age int } func main() { person := \u0026amp;Person{28} defer fmt.Println(person.age) defer func(p *Person) { fmt.Println(p.age) }(person) defer func() { fmt.","tags":null,"title":"Defer"},{"categories":null,"contents":" goroutine package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ch1 := make(chan int) go fmt.Println(\u0026lt;-ch1) ch1 \u0026lt;- 5 time.Sleep(1 * time.Second) } A. 5 B. deadlock C. compilation error Answer Try it B ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/goroutine/","summary":" goroutine package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ch1 := make(chan int) go fmt.Println(\u0026lt;-ch1) ch1 \u0026lt;- 5 time.Sleep(1 * time.Second) } A. 5 B. deadlock C. compilation error Answer Try it B ","tags":null,"title":"Goroutine"},{"categories":null,"contents":" interface package main import ( \u0026#34;fmt\u0026#34; ) type People interface { Show() } type Student struct{} func (stu *Student) Show() { } func live() People { var stu *Student return stu } func main() { if live() == nil { fmt.Println(\u0026#34;AAAAAAA\u0026#34;) } else { fmt.Println(\u0026#34;BBBBBBB\u0026#34;) } } Answer Try it BBBBBBB interface1 package main import ( \u0026#34;fmt\u0026#34; ) type People interface { Speak(string) string } type Student struct{} func (stu *Student) Speak(think string) (talk string) { if think == \u0026#34;love\u0026#34; { talk = \u0026#34;You are a good boy\u0026#34; } else { talk = \u0026#34;hi\u0026#34; } return } func main() { var peo People = Student{} think := \u0026#34;love\u0026#34; fmt.Println(peo.Speak(think)) } Answer Try it compilation error cannot use Student{} (value of type Student) as People value in variable declaration: Student does not implement People (method Speak has pointer receiver) interface2 package main import \u0026#34;fmt\u0026#34; type T1 struct { String func() string } func (T1) Error() string { return \u0026#34;T1.Error\u0026#34; } type T2 struct { Error func() string } func (T2) String() string { return \u0026#34;T2.String\u0026#34; } var t1 = T1{String: func() string { return \u0026#34;T1.String\u0026#34; }} var t2 = T2{Error: func() string { return \u0026#34;T2.Error\u0026#34; }} func main() { fmt.Println(t1.Error(), t1.String()) fmt.Println(t2.Error(), t2.String()) fmt.Println(t1, t2) } Answer Try it T1.Error T1.String T2.Error T2.String T1.Error T2.String interface3 package main import \u0026#34;fmt\u0026#34; func main() { var p [100]int var m interface{} = [...]int{99: 0} fmt.Println(p == m) } Answer Try it true ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/interface/","summary":"interface package main import ( \u0026#34;fmt\u0026#34; ) type People interface { Show() } type Student struct{} func (stu *Student) Show() { } func live() People { var stu *Student return stu } func main() { if live() == nil { fmt.Println(\u0026#34;AAAAAAA\u0026#34;) } else { fmt.Println(\u0026#34;BBBBBBB\u0026#34;) } } Answer Try it BBBBBBB interface1 package main import ( \u0026#34;fmt\u0026#34; ) type People interface { Speak(string) string } type Student struct{} func (stu *Student) Speak(think string) (talk string) { if think == \u0026#34;love\u0026#34; { talk = \u0026#34;You are a good boy\u0026#34; } else { talk = \u0026#34;hi\u0026#34; } return } func main() { var peo People = Student{} think := \u0026#34;love\u0026#34; fmt.","tags":null,"title":"Interface"},{"categories":null,"contents":" iota package main import \u0026#34;fmt\u0026#34; const ( x = iota _ y z = \u0026#34;zz\u0026#34; k p = iota ) func main() { fmt.Println(x, y, z, k, p) } Answer Try it 0 2 zz zz 5 iota1 package main import \u0026#34;fmt\u0026#34; const ( a = iota b = iota ) const ( name = \u0026#34;name\u0026#34; c = iota d = iota ) func main() { fmt.Println(a, b, c, d) } Answer Try it 0 1 1 2 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/iota/","summary":" iota package main import \u0026#34;fmt\u0026#34; const ( x = iota _ y z = \u0026#34;zz\u0026#34; k p = iota ) func main() { fmt.Println(x, y, z, k, p) } Answer Try it 0 2 zz zz 5 iota1 package main import \u0026#34;fmt\u0026#34; const ( a = iota b = iota ) const ( name = \u0026#34;name\u0026#34; c = iota d = iota ) func main() { fmt.Println(a, b, c, d) } Answer Try it 0 1 1 2 ","tags":null,"title":"Iota"},{"categories":null,"contents":" json package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type AutoGenerated struct { Age int `json:\u0026#34;age\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` Child []int `json:\u0026#34;child\u0026#34;` } func main() { jsonStr1 := `{\u0026#34;age\u0026#34;: 14,\u0026#34;name\u0026#34;: \u0026#34;potter\u0026#34;, \u0026#34;child\u0026#34;:[1,2,3]}` a := AutoGenerated{} json.Unmarshal([]byte(jsonStr1), \u0026amp;a) aa := a.Child fmt.Println(aa) jsonStr2 := `{\u0026#34;age\u0026#34;: 12,\u0026#34;name\u0026#34;: \u0026#34;potter\u0026#34;, \u0026#34;child\u0026#34;:[3,4,5,7,8,9]}` json.Unmarshal([]byte(jsonStr2), \u0026amp;a) fmt.Println(aa) } A. [1 2 3] [1 2 3] B. [1 2 3] [3 4 5] C. [1 2 3] [3 4 5 6 7 8 9] D. [1 2 3] [3 4 5 0 0 0] Answer Try it B json1 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { t := struct { time.Time N int }{ time.Date(2020, 12, 20, 0, 0, 0, 0, time.UTC), 5, } m, _ := json.Marshal(t) fmt.Printf(\u0026#34;%s\u0026#34;, m) } A. {\u0026ldquo;Time\u0026rdquo;:\u0026ldquo;2020-12-20T00:00:00Z\u0026rdquo;,\u0026ldquo;N\u0026rdquo;:5} B. \u0026ldquo;2020-12-20T00:00:00Z\u0026rdquo; C. {\u0026ldquo;N\u0026rdquo;:5} D. E. 其他 Answer Try it B ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/json/","summary":"json package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type AutoGenerated struct { Age int `json:\u0026#34;age\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` Child []int `json:\u0026#34;child\u0026#34;` } func main() { jsonStr1 := `{\u0026#34;age\u0026#34;: 14,\u0026#34;name\u0026#34;: \u0026#34;potter\u0026#34;, \u0026#34;child\u0026#34;:[1,2,3]}` a := AutoGenerated{} json.Unmarshal([]byte(jsonStr1), \u0026amp;a) aa := a.Child fmt.Println(aa) jsonStr2 := `{\u0026#34;age\u0026#34;: 12,\u0026#34;name\u0026#34;: \u0026#34;potter\u0026#34;, \u0026#34;child\u0026#34;:[3,4,5,7,8,9]}` json.Unmarshal([]byte(jsonStr2), \u0026amp;a) fmt.Println(aa) } A. [1 2 3] [1 2 3] B. [1 2 3] [3 4 5] C. [1 2 3] [3 4 5 6 7 8 9] D.","tags":null,"title":"JSON"},{"categories":null,"contents":" len package main func main() { var x *struct { s [][32]byte } println(len(x.s[99])) } A. panic B. compilation error C. 32 D. 0 Answer Try it C len1 package main const s = \u0026#34;Go101.org\u0026#34; // len(s) == 9 // 1 \u0026lt;\u0026lt; 9 == 512 // 512 / 128 == 4 var a byte = 1 \u0026lt;\u0026lt; len(s) / 128 var b byte = 1 \u0026lt;\u0026lt; len(s[:]) / 128 func main() { println(a, b) } A: 0 0 B: 0 4 C: 4 0 D: 4 4 Answer Try it C len2 package main var s = \u0026#34;Go101.org\u0026#34; // len(s) == 9 // 1 \u0026lt;\u0026lt; 9 == 512 // 512 / 128 == 4 var a byte = 1 \u0026lt;\u0026lt; len(s) / 128 var b byte = 1 \u0026lt;\u0026lt; len(s[:]) / 128 func main() { println(a, b) } A: 0 0 B: 0 4 C: 4 0 D: 4 4 Answer Try it A ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/len/","summary":"len package main func main() { var x *struct { s [][32]byte } println(len(x.s[99])) } A. panic B. compilation error C. 32 D. 0 Answer Try it C len1 package main const s = \u0026#34;Go101.org\u0026#34; // len(s) == 9 // 1 \u0026lt;\u0026lt; 9 == 512 // 512 / 128 == 4 var a byte = 1 \u0026lt;\u0026lt; len(s) / 128 var b byte = 1 \u0026lt;\u0026lt; len(s[:]) / 128 func main() { println(a, b) } A: 0 0 B: 0 4 C: 4 0 D: 4 4 Answer Try it C len2 package main var s = \u0026#34;Go101.","tags":null,"title":"Len"},{"categories":null,"contents":" map package main import \u0026#34;fmt\u0026#34; type Student struct { Name string } var list map[string]Student func main() { list = make(map[string]Student) student := Student{\u0026#34;Aceld\u0026#34;} list[\u0026#34;student\u0026#34;] = student list[\u0026#34;student\u0026#34;].Name = \u0026#34;LDB\u0026#34; fmt.Println(list[\u0026#34;student\u0026#34;]) } Answer Try it compilation error cannot assign to struct field list[\"student\"].Name in map map1 package main func main() { m := make(map[int]int, 3) x := len(m) m[1] = m[1] y := len(m) println(x, y) } Answer Try it 0 1 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/map/","summary":" map package main import \u0026#34;fmt\u0026#34; type Student struct { Name string } var list map[string]Student func main() { list = make(map[string]Student) student := Student{\u0026#34;Aceld\u0026#34;} list[\u0026#34;student\u0026#34;] = student list[\u0026#34;student\u0026#34;].Name = \u0026#34;LDB\u0026#34; fmt.Println(list[\u0026#34;student\u0026#34;]) } Answer Try it compilation error cannot assign to struct field list[\"student\"].Name in map map1 package main func main() { m := make(map[int]int, 3) x := len(m) m[1] = m[1] y := len(m) println(x, y) } Answer Try it 0 1 ","tags":null,"title":"Map"},{"categories":null,"contents":" print package main import \u0026#34;fmt\u0026#34; type T struct { x int } func (t T) String() string { return \u0026#34;boo\u0026#34; } func main() { t := T{123} fmt.Printf(\u0026#34;%v\\n\u0026#34;, t) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, t) } Answer Try it boo main.T{x:123} print1 package main import ( \u0026#34;fmt\u0026#34; ) func f(a ...int) { fmt.Printf(\u0026#34;%#v\\n\u0026#34;, a) } func main() { f() } Answer Try it []int(nil) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/print/","summary":" print package main import \u0026#34;fmt\u0026#34; type T struct { x int } func (t T) String() string { return \u0026#34;boo\u0026#34; } func main() { t := T{123} fmt.Printf(\u0026#34;%v\\n\u0026#34;, t) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, t) } Answer Try it boo main.T{x:123} print1 package main import ( \u0026#34;fmt\u0026#34; ) func f(a ...int) { fmt.Printf(\u0026#34;%#v\\n\u0026#34;, a) } func main() { f() } Answer Try it []int(nil) ","tags":null,"title":"Print"},{"categories":null,"contents":" race type Stats struct { mutex sync.Mutex counters map[string]int } func (s *Stats) Snapshot() map[string]int { s.mutex.Lock() defer s.mutex.Unlock() return s.counters } func (s *Stats) Add(name string, num int) { s.mutex.Lock() defer s.mutex.Unlock() s.counters[name] = num } Answer func (s *Stats) Snapshot() map[string]int { s.mutex.Lock() defer s.mutex.Unlock() result := make(map[string]int, len(s.counters)) for k, v := range s.counters { result[k] = v } return result } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/race/","summary":" race type Stats struct { mutex sync.Mutex counters map[string]int } func (s *Stats) Snapshot() map[string]int { s.mutex.Lock() defer s.mutex.Unlock() return s.counters } func (s *Stats) Add(name string, num int) { s.mutex.Lock() defer s.mutex.Unlock() s.counters[name] = num } Answer func (s *Stats) Snapshot() map[string]int { s.mutex.Lock() defer s.mutex.Unlock() result := make(map[string]int, len(s.counters)) for k, v := range s.counters { result[k] = v } return result } ","tags":null,"title":"Race"},{"categories":null,"contents":" select package main import \u0026#34;sync\u0026#34; func main() { var wg sync.WaitGroup foo := make(chan int) bar := make(chan int) wg.Add(1) go func() { defer wg.Done() select { case foo \u0026lt;- \u0026lt;-bar: default: println(\u0026#34;default\u0026#34;) } }() wg.Wait() } Answer Try it fatal error: all goroutines are asleep - deadlock! select1 package main import \u0026#34;fmt\u0026#34; func main() { ch1 := make(chan int) ch2 := make(chan int) go func() { ch1 \u0026lt;- 1 }() go func() { select { case \u0026lt;-ch1: case ch2 \u0026lt;- 2: } }() fmt.Println(\u0026lt;-ch2) } A. 1 B. 2 C. No output, program is deadlocked D. No output, program has finished execution. E. else Answer Try it B ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/select/","summary":"select package main import \u0026#34;sync\u0026#34; func main() { var wg sync.WaitGroup foo := make(chan int) bar := make(chan int) wg.Add(1) go func() { defer wg.Done() select { case foo \u0026lt;- \u0026lt;-bar: default: println(\u0026#34;default\u0026#34;) } }() wg.Wait() } Answer Try it fatal error: all goroutines are asleep - deadlock! select1 package main import \u0026#34;fmt\u0026#34; func main() { ch1 := make(chan int) ch2 := make(chan int) go func() { ch1 \u0026lt;- 1 }() go func() { select { case \u0026lt;-ch1: case ch2 \u0026lt;- 2: } }() fmt.","tags":null,"title":"Select"},{"categories":null,"contents":" slice package main import ( \u0026#34;fmt\u0026#34; ) func main() { var s1 []int var s2 = []int{} if __ == nil { fmt.Println(\u0026#34;nil slice\u0026#34;) } if __ != nil { fmt.Println(\u0026#34;empty slice\u0026#34;) } } A. s1, s2 B. s2, s1 C. s1, s1 D. s2, s2 Answer Try it A slice1 package main import ( \u0026#34;fmt\u0026#34; ) func main() { s := [3]int{1, 2, 3} a := s[:0] b := s[:2] c := s[1:2:cap(s)] fmt.Println(len(a), cap(a)) fmt.Println(len(b), cap(b)) fmt.Println(len(c), cap(c)) } Answer Try it 0 3 2 3 1 2 slice2 package main import \u0026#34;fmt\u0026#34; func main() { s1 := []int{1, 2, 3} s2 := s1[1:] s2[1] = 4 fmt.Println(s1) s2 = append(s2, 5, 6, 7) fmt.Println(s1) } Answer Try it [1 2 4] [1 2 4] ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/slice/","summary":"slice package main import ( \u0026#34;fmt\u0026#34; ) func main() { var s1 []int var s2 = []int{} if __ == nil { fmt.Println(\u0026#34;nil slice\u0026#34;) } if __ != nil { fmt.Println(\u0026#34;empty slice\u0026#34;) } } A. s1, s2 B. s2, s1 C. s1, s1 D. s2, s2 Answer Try it A slice1 package main import ( \u0026#34;fmt\u0026#34; ) func main() { s := [3]int{1, 2, 3} a := s[:0] b := s[:2] c := s[1:2:cap(s)] fmt.","tags":null,"title":"Slice"},{"categories":null,"contents":" variable A. p.name B. (\u0026amp;p).name C. (*p).name D. p-\u0026gt;name Answer AC variable1 package main import ( \u0026#34;fmt\u0026#34; ) func main() { var ans float64 = 15 + 25 + 5.2 fmt.Println(ans) } A. 45 B. 45.0 C. 45.2 D. compliation error Answer Try it C variable2 package main import ( \u0026#34;fmt\u0026#34; ) func main() { var ans float64 = 3 / 2 fmt.Println(ans) } A. 1.5 B. 1 C. 0 D. compliation error Answer Try it B variable3 package main func main() { const a int8 = -1 var b int8 = -128 / a println(b) } Answer Try it compliation error -128 / a (constant 128 of type int8) overflows int8 variable4 package main func main() { var a int8 = -1 var b int8 = -128 / a println(b) } Answer Try it -128 variable5 package main import \u0026#34;fmt\u0026#34; type MyInt1 int type MyInt2 = int func main() { var i int =0 var i1 MyInt1 = i var i2 MyInt2 = i fmt.Println(i1, i2) } Answer Try it compilation error cannot use i (variable of type int) as MyInt1 value in variable declaration variable6 package main import \u0026#34;fmt\u0026#34; func main() { const X = 7.0 var x interface{} = X if y, ok := x.(int); ok { fmt.Println(y) } else { fmt.Println(int(y)) } } A. 7 B. 7.0 C. 0 D. compilation error Answer Try it C ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/notes/go/questions/variable/","summary":"variable A. p.name B. (\u0026amp;p).name C. (*p).name D. p-\u0026gt;name Answer AC variable1 package main import ( \u0026#34;fmt\u0026#34; ) func main() { var ans float64 = 15 + 25 + 5.2 fmt.Println(ans) } A. 45 B. 45.0 C. 45.2 D. compliation error Answer Try it C variable2 package main import ( \u0026#34;fmt\u0026#34; ) func main() { var ans float64 = 3 / 2 fmt.Println(ans) } A. 1.5 B. 1 C. 0 D.","tags":null,"title":"Variable"},{"categories":["Kubernetes","Docker","Container","Linux","Security","URL"],"contents":"Container security fundamentals\n","date":"October 4, 2023","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/posts/20231004container/","summary":"Container security fundamentals","tags":["Kubernetes","Docker","Container","Linux","Security","URL"],"title":"Container security fundamentals"},{"categories":["Kubernetes","MQTT","EMQX","Linux","URL"],"contents":"Reference Tuning EMQX to Scale to One Million Concurrent Connection on Kubernetes Performance Tuning (Linux) 矽谷牛的耕田筆記 Note Linux Kernel Tuning node level, basically the non-namespaced sysctls # Sets the maximum number of file handles allowed by the kernel sysctl -w fs.file-max=2097152 # Sets the maximum number of open file descriptors that a process can have sysctl -w fs.nr_open=2097152 namespaced sysctls # Sets the maximum number of connections that can be queued for acceptance by the kernel. sysctl -w net.core.somaxconn=32768 # Sets the maximum number of SYN requests that can be queued by the kernel sysctl -w net.ipv4.tcp_max_syn_backlog=16384 # Setting the minimum, default and maximum size of TCP Buffer sysctl -w net.ipv4.tcp_rmem=\u0026#39;1024 4096 16777216\u0026#39; sysctl -w net.ipv4.tcp_wmem=\u0026#39;1024 4096 16777216\u0026#39; # Setting Parameters for TCP Connection Tracking sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=30 # Controls the maximum number of entries in the TCP time-wait bucket table sysctl -w net.ipv4.tcp_max_tw_buckets=1048576 # Controls Timeout for FIN-WAIT-2 Sockets: sysctl -w net.ipv4.tcp_fin_timeout=15 There are some more namespaced sysctls that will improve the performance but because of an active issue we are not able to set them on the container level # Sets the size of the backlog queue for the network device sysctl -w net.core.netdev_max_backlog=16384 # Amount of memory that is allocated for storing incoming and outgoing data for a socket sysctl -w net.core.rmem_default=262144 sysctl -w net.core.wmem_default=262144 # Setting the maximum amount of memory for the socket buffers sysctl -w net.core.rmem_max=16777216 sysctl -w net.core.wmem_max=16777216 sysctl -w net.core.optmem_max=16777216 Erlang VM Tuning ## Erlang Process Limit node.process_limit = 2097152 ## Sets the maximum number of simultaneously existing ports for this system node.max_ports = 2097152 EMQX Broker Tuning # Other configuration… EMQX_LISTENER__TCP__EXTERNAL: \u0026#34;0.0.0.0:1883\u0026#34; EMQX_LISTENER__TCP__EXTERNAL__ACCEPTORS: 64 EMQX_LISTENER__TCP__EXTERNAL__MAX_CONNECTIONS: 1024000 ","date":"September 27, 2023","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/posts/20230927mqtt/","summary":"Reference Tuning EMQX to Scale to One Million Concurrent Connection on Kubernetes Performance Tuning (Linux) 矽谷牛的耕田筆記 Note Linux Kernel Tuning node level, basically the non-namespaced sysctls # Sets the maximum number of file handles allowed by the kernel sysctl -w fs.file-max=2097152 # Sets the maximum number of open file descriptors that a process can have sysctl -w fs.nr_open=2097152 namespaced sysctls # Sets the maximum number of connections that can be queued for acceptance by the kernel.","tags":["Kubernetes","MQTT","EMQX","Linux","URL"],"title":"Tuning EMQX to Scale to One Million Concurrent Connection on Kubernetes"},{"categories":["Chrome OS","URL","Video"],"contents":"老電腦別丟掉！安裝 Google 免費作業系統安裝教學（Chrome OS Flex /CloudReady）\n","date":"September 27, 2023","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/posts/20230927chromeos/","summary":"老電腦別丟掉！安裝 Google 免費作業系統安裝教學（Chrome OS Flex /CloudReady）","tags":["Chrome OS","URL","Video"],"title":"Install Chrome OS"},{"categories":["AI","URL","Video"],"contents":"https://www.youtube.com/watch?v=M3z6gI1AEns\n","date":"September 27, 2023","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/posts/20230927ai/","summary":"https://www.youtube.com/watch?v=M3z6gI1AEns","tags":["AI","URL","Video"],"title":"永齡基金會AI大師論壇:人工智慧如何形塑人類未來"},{"categories":["Go","URL"],"contents":"Go 语言是一个高性能的语言，但并不是说这样我们就不用关心性能了，我们还是需要关心的。下面是一个在编程方面和性能相关的提示。\n如果需要把数字转字符串，使用 strconv.Itoa() 会比 fmt.Sprintf() 要快一倍左右 尽可能地避免把 String 转成[]Byte 。这个转换会导致性能下降。 如果在 for-loop 里对某个 slice 使用 append()请先把 slice 的容量很扩充到位，这样可以避免内存重新分享以及系统自动按 2 的 N 次方幂进行扩展但又用不到，从而浪费内存。 使用 StringBuffer 或是 StringBuild 来拼接字符串，会比使用 + 或 += 性能高三到四个数量级。 尽可能的使用并发的 go routine，然后使用 sync.WaitGroup 来同步分片操作 避免在热代码中进行内存分配，这样会导致 gc 很忙。尽可能的使用 sync.Pool 来重用对象。 使用 lock-free 的操作，避免使用 mutex，尽可能使用 sync/Atomic 包。 （关于无锁编程的相关话题，可参看《无锁队列实现》或《无锁 Hashmap 实现》） 使用 I/O 缓冲，I/O 是个非常非常慢的操作，使用 bufio.NewWrite() 和 bufio.NewReader() 可以带来更高的性能。 对于在 for-loop 里的固定的正则表达式，一定要使用 regexp.Compile() 编译正则表达式。性能会得升两个数量级。 如果你需要更高性能的协议，你要考虑使用 protobuf 或 msgp 而不是 JSON，因为 JSON 的序列化和反序列化里使用了反射。 你在使用 map 的时候，使用整型的 key 会比字符串的要快，因为整型比较比字符串比较要快。 Reference GO 编程模式：切片，接口，时间和性能 ","date":"September 26, 2023","hero":"/posts/20230926golang/2.svg","permalink":"https://linzeyan.github.io/posts/20230926golang/","summary":"Go 语言是一个高性能的语言，但并不是说这样我们就不用关心性能了，我们还是需要关心的。下面是一个在编程方面和性能相关的提示。\n如果需要把数字转字符串，使用 strconv.Itoa() 会比 fmt.Sprintf() 要快一倍左右 尽可能地避免把 String 转成[]Byte 。这个转换会导致性能下降。 如果在 for-loop 里对某个 slice 使用 append()请先把 slice 的容量很扩充到位，这样可以避免内存重新分享以及系统自动按 2 的 N 次方幂进行扩展但又用不到，从而浪费内存。 使用 StringBuffer 或是 StringBuild 来拼接字符串，会比使用 + 或 += 性能高三到四个数量级。 尽可能的使用并发的 go routine，然后使用 sync.WaitGroup 来同步分片操作 避免在热代码中进行内存分配，这样会导致 gc 很忙。尽可能的使用 sync.Pool 来重用对象。 使用 lock-free 的操作，避免使用 mutex，尽可能使用 sync/Atomic 包。 （关于无锁编程的相关话题，可参看《无锁队列实现》或《无锁 Hashmap 实现》） 使用 I/O 缓冲，I/O 是个非常非常慢的操作，使用 bufio.NewWrite() 和 bufio.NewReader() 可以带来更高的性能。 对于在 for-loop 里的固定的正则表达式，一定要使用 regexp.Compile() 编译正则表达式。性能会得升两个数量级。 如果你需要更高性能的协议，你要考虑使用 protobuf 或 msgp 而不是 JSON，因为 JSON 的序列化和反序列化里使用了反射。 你在使用 map 的时候，使用整型的 key 会比字符串的要快，因为整型比较比字符串比较要快。 Reference GO 编程模式：切片，接口，时间和性能 ","tags":["Go","URL"],"title":"Golang tips"},{"categories":["chart","data","visualization","URL"],"contents":"https://datavizproject.com\n","date":"September 26, 2023","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/posts/20230926datavizproject/","summary":"https://datavizproject.com","tags":["chart","data","visualization","URL"],"title":"datavizproject"},{"categories":["travel","checklist","URL"],"contents":"https://travel-questions.gnehs.net/\n","date":"September 26, 2023","hero":"/images/default-hero.jpg","permalink":"https://linzeyan.github.io/posts/20230926checklist/","summary":"https://travel-questions.gnehs.net/","tags":["travel","checklist","URL"],"title":"朋友旅行防止絕交檢查表"},{"categories":["Cloudflare","zero trust"],"contents":"Connect private networks 1. Set up the client Create device enrollment rules Create device enrollment rules to determine which devices can enroll to Zero Trust organization.\nSet device enrollment permissions In Zero Trust, go to Settings \u0026gt; WARP Client \u0026gt; Device enrollment \u0026gt; Device enrollment permissions \u0026gt; Manage. Rules \u0026gt; Policies \u0026gt; Add a rule \u0026gt; Include \u0026gt; Selector \u0026gt; Emails ending in \u0026gt; Value \u0026gt; @ruru910.com. 2. Route private network IPs through WARP In Zero Trust, go to Settings \u0026gt; WARP Client \u0026gt; Device settings \u0026gt; Profile settings \u0026gt; Profile name \u0026gt; Default \u0026gt; Configure. Configure settings: Enabled: Captive portal detection, Mode switch, Allow device to leave organization, Allow updates. Service mode: Gateway with WARP. Local Domain Fallback \u0026gt; Manage \u0026gt; Domain \u0026gt; nas.ruru910.com. Split Tunnels: Exclude IPs and domains \u0026gt; Manage. Delete the IP range of nas.ruru910.com. 3. Filter network traffic with Gateway 1. Enable the Gateway proxy In Zero Trust, go to Settings \u0026gt; Network. Gateway Logging: Capture all. Firewall: Proxy(TCP, UDP, ICMP), WARP to WARP, AV inspection. 2. Create Zero Trust policies Go to Access \u0026gt; Applications \u0026gt; Add an application \u0026gt; Private Network \u0026gt; Application Type \u0026gt; Destination IP. For Value, enter the IP address for your application (for example, 10.128.0.7). Modify policy \u0026gt; identify \u0026gt; Selector \u0026gt; User Email \u0026gt; in \u0026gt; @ruru910.com. Reference Connect private networks Configure Local Domain Fallback Configure Split Tunnels Traffic routing with WARP ","date":"September 26, 2023","hero":"/posts/20230926cloudflare/cloudflare.svg","permalink":"https://linzeyan.github.io/posts/20230926cloudflare/","summary":"Connect private networks 1. Set up the client Create device enrollment rules Create device enrollment rules to determine which devices can enroll to Zero Trust organization.\nSet device enrollment permissions In Zero Trust, go to Settings \u0026gt; WARP Client \u0026gt; Device enrollment \u0026gt; Device enrollment permissions \u0026gt; Manage. Rules \u0026gt; Policies \u0026gt; Add a rule \u0026gt; Include \u0026gt; Selector \u0026gt; Emails ending in \u0026gt; Value \u0026gt; @ruru910.com. 2. Route private network IPs through WARP In Zero Trust, go to Settings \u0026gt; WARP Client \u0026gt; Device settings \u0026gt; Profile settings \u0026gt; Profile name \u0026gt; Default \u0026gt; Configure.","tags":["Cloudflare","zero trust"],"title":"Cloudflare Zero Trust"},{"categories":["Cloudflare","Synology"],"contents":"Setup Synology Create a directory in docker directory, such as cloudflare-tunnel. Download cloudflared/cloudflared image to registry. ssh to admin@synology Change cloudflare-tunnel owner, sudo chown -R 65532:65532 /volume1/docker/cloudflare-tunnel. Run containers - cloudflared tunnel login Run container and mount volume docker/cloudflare-tunnel:/home/nonroot/.cloudflared. Select Use the same network as Docker Host in network tab. Add command tunnel login in envorinment tab. Go to container log, and copy login url. Paste url to browser and authorize the zone. Export the container setting json to the directory cloudflare-tunnel. - cloudflared tunnel create synology-tunnel Edit the container setting json in the the directory cloudflare-tunnel, modify cmd. tunnel create synology-tunnel. Import the container setting json and run a new container. The container will stop and create tunnel config json in cloudflare-tunnel. Create config.yml and write ingress rules. In config.yml, tunnel value is the same as the tunnel config json name, and credentials-file is /home/nonroot/.cloudflared/tunnel config json Export the second container setting json to the directory cloudflare-tunnel. - cloudflared tunnel route dns synology-tunnel synology.ruru910.com Edit the second container setting json in the the directory cloudflare-tunnel, modify cmd. tunnel route dns synology-tunnel synology.ruru910.com. Import the second container setting json and run a new container. The container will stop and create a dns record mapping domain to the tunnel. - cloudflared tunnel run synology-tunnel Edit the second container setting json in the the directory cloudflare-tunnel, modify cmd. tunnel run synology-tunnel. Import the second container setting json and run a new container. The tunnel now is connectable. Reference CLOUDFLARE tunnel on SYNOLOGY. (the raw way) ","date":"September 25, 2023","hero":"/posts/20230925cloudflare/cloudflare.svg","permalink":"https://linzeyan.github.io/posts/20230925cloudflare/","summary":"Setup Synology Create a directory in docker directory, such as cloudflare-tunnel. Download cloudflared/cloudflared image to registry. ssh to admin@synology Change cloudflare-tunnel owner, sudo chown -R 65532:65532 /volume1/docker/cloudflare-tunnel. Run containers - cloudflared tunnel login Run container and mount volume docker/cloudflare-tunnel:/home/nonroot/.cloudflared. Select Use the same network as Docker Host in network tab. Add command tunnel login in envorinment tab. Go to container log, and copy login url. Paste url to browser and authorize the zone.","tags":["Cloudflare","tunnel","Synology"],"title":"Cloudflare tunnel on Synology"},{"categories":["Nginx"],"contents":"Record Nginx configuration file and explanation. files structure . ├── geoip.conf ├── nginx.conf ├── sites-available │ ├── default.conf ├── sites-enabled │ ├── default.conf -\u0026gt; ../sites-available/default.conf ├── upstream.conf geoip.conf ## module: ngx_http_geoip2_module ## https://github.com/leev/ngx_http_geoip2_module ## 讀取 GeoIP 資料庫，並進行變數設定 geoip2 /usr/share/GeoIP/GeoLite2-Country.mmdb { auto_reload 60m; $geoip2_metadata_country_build metadata build_epoch; ## 自定義 $geoip2_data_country_code 值為 $remote_addr 對應的 ISO 3116 規範的國碼 $geoip2_data_country_code source=$remote_addr country iso_code; ## 自定義 $geoip2_data_country_name 值為對應的英文城市名 $geoip2_data_country_name country names en; } upstream.conf ## module: ngx_http_upstream_module ## 定義 server 組別 upstream to_nodejs1 { ## server address [parameters]; 定義 server ## parameters: ## weight=number 定義權重，預設為 1 ## max_fails=number 設定到 upstream server 的最大重試次數，預設為 1 ## fail_timeout=time 設定到達 max_fails 次數之後，暫停向此 upstream server 傳送請求的時間，預設為 10 秒 ## backup 標記此 upstream server 為備用，當其他 upstream server 不可用時，此 upstream server 可接受請求 ## down 標記此 upstream server 為不可用 server 10.7.0.12:9000 max_fails=3 fail_timeout=5s; server 10.7.0.12:9001 max_fails=3 fail_timeout=5s backup; } upstream to_nodejs2 { server 10.7.0.12:9002 max_fails=3 fail_timeout=5s; server 10.7.0.12:9003 max_fails=3 fail_timeout=5s backup; } upstream to_nodejs9005 { server 10.7.0.12:9005 max_fails=3 fail_timeout=5s; } ## module: ngx_http_map_module ## map string $variable { ... } 建立一個新的變數 map $arg_agent $game_api { ## $arg_agent 請求中 agent 的值(https://abc.com/?agent=123) ## agent=123, $game_api 的值為 to_nodejs95 123 to_nodejs95; ## agent 結尾是 1, 2, 3, 或是 4, $game_api 的值為 to_nodejs1 ~*1$ to_nodejs1; ~*2$ to_nodejs1; ~*3$ to_nodejs1; ~*4$ to_nodejs1; ## 若 agent 不符合上開規則，預設 $game_api 的值為 to_nodejs2 default to_nodejs2; } default.conf ## module: ngx_http_limit_req_module ## 限制請求處理 ## limit_req_zone key zone=name:size rate=rate [sync]; 定義限制請求的規則 limit_req_zone $binary_remote_addr$server_name zone=websocket:10m rate=1r/m; ## limit_req_status code; 設定被拒絕連線的 HTTP 狀態碼，預設為 503 limit_req_status 502; ## 設定虛擬主機 server { ## listen port [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; ## 設定監聽的埠口，預設為 *:80 ## 下方設定為監聽 80 port，且為預設的虛擬主機 listen 80 default_server; ## server_name name ...; 設定虛擬主機名，可使用正則表示式，預設為 \u0026#34;\u0026#34; server_name _; access_log logs/default/default.log json; error_log logs/default/default.error.log warn; ## module: ngx_http_access_module ## allow address | CIDR | unix: | all; 允許 IP 訪問 allow 1.1.1.1; ## deny address | CIDR | unix: | all; 禁止 IP 訪問 deny 12.34.56.78; ## 設定請求訪問的根資料夾 root /usr/share/nginx/html; ## limit_req zone=name [burst=number] [nodelay | delay=number]; 設定限制請求的規則 zone limit_req zone=websocket nodelay; ## limit_req_log_level info | notice | warn | error; 設定被拒絕連線的請求日誌等級，預設為 error limit_req_log_level warn; ## location [ = | ~ | ~* | ^~ ] uri { ... } ## location @name { ... } 依據請求的 URI 配置 location / { default_type application/json; ## 返回 HTTP 狀態碼 200，並包含字串 return 200 \u0026#39;{\u0026#34;Code\u0026#34;: \u0026#34;$status\u0026#34;, \u0026#34;IP\u0026#34;: \u0026#34;$remote_addr\u0026#34;}\u0026#39;; } } server { ## 下方設定為監聽 443 port，且為預設的虛擬主機，所有連線都使用 SSL listen 443 default_server ssl; server_name _; access_log logs/default/default.log json; error_log logs/default/default.error.log warn; ## module: ngx_http_ssl_module ## 設定 PEM 格式的證書 ssl_certificate /etc/ssl/hddv1.com.crt; ## 設定 PEM 格式的密鑰 ssl_certificate_key /etc/ssl/hddv1.com.key; ## 設定 SSL 版本，預設為 TLSv1 TLSv1.1 TLSv1.2 ssl_protocols TLSv1.2 TLSv1.3; ## 設定啟用的加密方法，預設為 HIGH:!aNULL:!MD5 ssl_ciphers \u0026#34;EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC2:!RC4:!aNULL:!eNULL:!LOW:!IDEA:!DES:!TDES:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!EXPORT:!ANON\u0026#34;; ## 為 DHE 加密法指定帶有 DH 參數的文件 ssl_dhparam /etc/ssl/dhparams.pem; ## 是否優先使用 server 的加密法，預設為 off ssl_prefer_server_ciphers on; ## ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; ## 設定緩存及大小，預設為 none ssl_session_cache shared:SSL:1m; ## 設定 session 可重複使用的時間，預設為 5 分鐘 ssl_session_timeout 5m; add_header X-Frame-Options \u0026#34;SAMEORIGIN\u0026#34;; add_header X-XSS-Protection \u0026#34;1; mode=block\u0026#34;; add_header Strict-Transport-Security \u0026#34;max-age=31536000; includeSubdomains; preload\u0026#34;; root /usr/share/nginx/html; limit_req zone=websocket nodelay; limit_req_log_level warn; default_type application/json; location / { default_type application/json; return 200 \u0026#39;{\u0026#34;Code\u0026#34;: \u0026#34;$status\u0026#34;, \u0026#34;IP\u0026#34;: \u0026#34;$remote_addr\u0026#34;}\u0026#39;; } } nginx.conf ## module: ngx_core_module ## worker_processes number | auto; 啟動 Nginx worker 程序數量, 設定 auto 即和 CPU 的數量相等 worker_processes auto; ## worker_rlimit_nofile number; Nginx worker 程序最大打開文件數，預設為系統 RLIMIT_NOFILE worker_rlimit_nofile 131072; ## worker_shutdown_timeout time; 設定關閉超時時間，當執行 reload 或是其他相關指令，超過 time 時間之後，Nginx 會主動關閉所有受影響的 worker worker_shutdown_timeout 60; ## error_log file [level]; 設定錯誤日誌寫入位置 ## debug, info, notice, warn, error, crit, alert, emerg error_log logs/error.log warn; ## pid file; 主程序 ID 文件位置 pid logs/nginx.pid; ## module: ngx_core_module ## 設定連線處理相關 events { ## worker_connections number; 單個 Nginx worker 程序的最大並發連接數，預設為 512，需要小於 worker_rlimit_nofile ## 最大連接數 = worker_connections * worker_processes worker_connections 102400; ## accept_mutex on | off; 預設為 off ## 只有一個新連線進入，如果設定為 on，只有一個 worker 會接受連線，其餘持續休眠 ## 如果設定為 off，所有 worker 會被喚醒，只有一個 worker 會接受連線，其餘重新休眠 ## 業務上使用 TCP 長連線、流量大，off 的效能以及 QPS 表現較佳 accept_mutex off; ## multi_accept on | off; 是否同時接受所有的請求，預設為 off multi_accept on; } ## module: ngx_http_core_module ## 設定 HTTP server 相關 http { ## module: ngx_core_module ## include file | mask; 使用文件中的設定 ## 下方為設定 MIME 類型,類型由 mime.type 文件定義 include mime.types; ## default_type mime-type; 定義默認 MIME 類型，預設為 text/plain default_type application/octet-stream; ## server_names_hash_max_size size; 設定 server_name 的 hash 表最大值，預設為 512 kb server_names_hash_max_size 2048; ## 設定 server_name 的 hash 表的大小，用於快速找到對應的 server_name，預設值取決於 CPU 的 L1 cache server_names_hash_bucket_size 256; ## server_tokens on | off | build | string; 是否在 Nginx 錯誤頁面顯示 Nginx 版本，預設為 on server_tokens off; ## 是否在錯誤日誌記錄 404 log_not_found off; ## 是否啟用 sendfile() 提高文件傳輸效率，預設為 off sendfile on; ## 文件是否使用完整封包發送，預設為 off tcp_nopush on; ## 數據是否儘快傳送，預設為 on tcp_nodelay on; ## 設定長連線持續秒數，超過時間 Nginx 會主動關閉連線，預設為 75 keepalive_timeout 70; ## client_max_body_size size; 設定請求允許最大的 body 大小 client_max_body_size 64M; ## module: ngx_http_gzip_module ## 是否啟用 gzip 壓縮，預設為 off gzip on; ## 設定要壓縮的 Content-Length 最小值，預設為 20 gzip_min_length 1k; ## 設定壓縮緩衝大小，預設為一頁記憶體 ## gzip_buffers number size; gzip_buffers 4 32k; ## 設定壓縮等級，範圍 1 ~ 9，預設為 1 gzip_comp_level 7; ## 設定要壓縮的 MIME 類型，預設為 text/html gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php application/json; ## 是否在 HTTP response header 增加 Vary: Accept-Encoding，預設為 off gzip_vary on; ## 針對特定 User-Agent 禁用壓縮 ## 下方為設定禁用 IE 6 gzip_disable \u0026#34;MSIE [1-6]\\.\u0026#34;; ## resolver address ... [valid=time] [ipv6=on|off] [status_zone=zone]; 使用指定的 NS 解析 server_name, upstream server 等 resolver 114.114.114.114 8.8.8.8 1.1.1.1; ## module: ngx_http_headers_module ## add_header name value [always]; 在 HTTP response header 增加欄位 ## 下方為設定允許跨域 add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Headers DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type; add_header Access-Control-Allow-Methods GET,POST,OPTIONS; add_header Access-Control-Expose-Headers \u0026#39;WWW-Authenticate,Server-Authorization,User-Identity-Token\u0026#39;; ## module: ngx_http_realip_module ## set_real_ip_from address | CIDR | unix:; 設定信任的可被替代的伺服器 IP，如反向代理伺服器 set_real_ip_from 10.0.0.0/8; set_real_ip_from 172.16.0.0/12; set_real_ip_from 192.168.0.0/16; ## real_ip_header field | X-Real-IP | X-Forwarded-For | proxy_protocol; 定義使用哪個標頭取代獲取到的 client IP，預設為 X-Real-IP real_ip_header X-Forwarded-For; ## 將 real_ip_header 設定的標頭中，「最後一個非信任伺服器 IP」或是「最後一個 IP」當成真實 IP，預設為 off real_ip_recursive on; ## module: ngx_http_log_module ## log_format name [escape=default|json|none] string ...; 設定日誌格式 log_format json escape=json \u0026#39;{\u0026#34;@timestamp\u0026#34;:\u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;@source\u0026#34;:\u0026#34;$server_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;ip\u0026#34;:\u0026#34;$http_x_forwarded_for\u0026#34;,\u0026#39; \u0026#39;\u0026#34;client\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request_method\u0026#34;:\u0026#34;$request_method\u0026#34;,\u0026#39; \u0026#39;\u0026#34;scheme\u0026#34;:\u0026#34;$scheme\u0026#34;,\u0026#39; \u0026#39;\u0026#34;domain\u0026#34;:\u0026#34;$server_name\u0026#34;,\u0026#39; \u0026#39;\u0026#34;client_host\u0026#34;:\u0026#34;$host\u0026#34;,\u0026#39; \u0026#39;\u0026#34;referer\u0026#34;:\u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request\u0026#34;:\u0026#34;$request_uri\u0026#34;,\u0026#39; \u0026#39;\u0026#34;args\u0026#34;:\u0026#34;$args\u0026#34;,\u0026#39; \u0026#39;\u0026#34;sent_bytes\u0026#34;:$body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;:$status,\u0026#39; \u0026#39;\u0026#34;responsetime\u0026#34;:$request_time,\u0026#39; \u0026#39;\u0026#34;upstreamtime\u0026#34;:\u0026#34;$upstream_response_time\u0026#34;,\u0026#39; \u0026#39;\u0026#34;upstreamaddr\u0026#34;:\u0026#34;$upstream_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_user_agent\u0026#34;:\u0026#34;$http_user_agent\u0026#34;,\u0026#39; \u0026#39;\u0026#34;Country\u0026#34;:\u0026#34;$geoip2_data_country_name\u0026#34;,\u0026#39; \u0026#39;\u0026#34;State\u0026#34;:\u0026#34;$geoip2_data_state_name\u0026#34;,\u0026#39; \u0026#39;\u0026#34;City\u0026#34;:\u0026#34;$geoip2_data_city_name\u0026#34;,\u0026#39; \u0026#39;\u0026#34;https\u0026#34;:\u0026#34;$https\u0026#34;\u0026#39; \u0026#39;}\u0026#39;; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; ## access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; 設定日誌寫入位置以及使用的日誌名稱 ## access_log off; 不紀錄日誌 access_log logs/access.log json; } ","date":"November 19, 2021","hero":"/posts/20211119nginx/nginx.jpeg","permalink":"https://linzeyan.github.io/posts/20211119nginx/","summary":"Record Nginx configuration file and explanation. files structure . ├── geoip.conf ├── nginx.conf ├── sites-available │ ├── default.conf ├── sites-enabled │ ├── default.conf -\u0026gt; ../sites-available/default.conf ├── upstream.conf geoip.conf ## module: ngx_http_geoip2_module ## https://github.com/leev/ngx_http_geoip2_module ## 讀取 GeoIP 資料庫，並進行變數設定 geoip2 /usr/share/GeoIP/GeoLite2-Country.mmdb { auto_reload 60m; $geoip2_metadata_country_build metadata build_epoch; ## 自定義 $geoip2_data_country_code 值為 $remote_addr 對應的 ISO 3116 規範的國碼 $geoip2_data_country_code source=$remote_addr country iso_code; ## 自定義 $geoip2_data_country_name 值為對應的英文城市名 $geoip2_data_country_name country names en; } upstream.conf ## module: ngx_http_upstream_module ## 定義 server 組別 upstream to_nodejs1 { ## server address [parameters]; 定義 server ## parameters: ## weight=number 定義權重，預設為 1 ## max_fails=number 設定到 upstream server 的最大重試次數，預設為 1 ## fail_timeout=time 設定到達 max_fails 次數之後，暫停向此 upstream server 傳送請求的時間，預設為 10 秒 ## backup 標記此 upstream server 為備用，當其他 upstream server 不可用時，此 upstream server 可接受請求 ## down 標記此 upstream server 為不可用 server 10.","tags":["Nginx","config"],"title":"Nginx notes"},{"categories":["Gitlab","CI"],"contents":"Gitlab CI Concept Gitlab DevOps GitOps Workflow code push -\u0026gt; pipeline -\u0026gt; stage -\u0026gt; job Design plan -\u0026gt; code -\u0026gt; build -\u0026gt; test -\u0026gt; release -\u0026gt; deploy -\u0026gt; operate -\u0026gt; monitor -\u0026gt; plan Runner Executors Shell VirtualBox Docker Docker Machine Kubernetes Else\u0026hellip; References Gitlab CI/CD Gitlab Runner .gitlab-ci.yaml Runner Register gitlab-runner register\nAfter register concurrent = 1 check_interval = 0 [session_server] session_timeout = 1800 [[runners]] name = \u0026#34;public-shell\u0026#34; url = \u0026#34;https://gitlab.go2cloudten.com/\u0026#34; token = \u0026#34;-mdH9OAOzG5yPsf_AVnW\u0026#34; executor = \u0026#34;shell\u0026#34; [[runners]] name = \u0026#34;public-docker\u0026#34; url = \u0026#34;https://gitlab.go2cloudten.com/\u0026#34; token = \u0026#34;AcEGPPKTS1uuQ_A_qpWy\u0026#34; executor = \u0026#34;docker\u0026#34; [runners.docker] dns = [\u0026#34;192.168.185.5\u0026#34;, \u0026#34;192.168.185.6\u0026#34;] tls_verify = false image = \u0026#34;registry.go2cloudten.com/it/office_sop/node:12.13.0\u0026#34; privileged = true disable_entrypoint_overwrite = false oom_kill_disable = false disable_cache = false shm_size = 0 pull_policy = \u0026#34;if-not-present\u0026#34; volumes = [\u0026#34;/cache\u0026#34;] Repository .gitlab-ci.yaml stages: - domain check-icp: stage: domain image: registry.go2cloudten.com/it/office_sop/icp tags: - docker script: - domains=$(awk -F \u0026#39;|\u0026#39; \u0026#39;{if($6 ~ \u0026#34;Y\u0026#34; \u0026amp;\u0026amp; ($7 ~ \u0026#34;West\u0026#34; || $7 ~ \u0026#34;Yuqu\u0026#34;)) print $3}\u0026#39; domains-info.md | sed \u0026#39;s/ //g\u0026#39; | sort | uniq) - if [[ \u0026#34;${domains}\u0026#34; == \u0026#34;\u0026#34; ]]; then telegram.sh \u0026#39;There is no domain in list\u0026#39; ; else telegram.sh \u0026#39;Start checking ICP.\u0026#39; ; fi - for i in ${domains}; do result=$(checkicp ${i}); if [[ \u0026#34;${result}\u0026#34; == \u0026#34;未备案\u0026#34; ]];then telegram.sh \u0026#34;${i} 未备案\u0026#34;; sleep 1 ;fi;done - telegram.sh \u0026#39;ICP check completed.\u0026#39; only: - schedules ","date":"September 24, 2021","hero":"/posts/20210924gitlab/gitlab.png","permalink":"https://linzeyan.github.io/posts/20210924gitlab/","summary":"Gitlab CI Concept Gitlab DevOps GitOps Workflow code push -\u0026gt; pipeline -\u0026gt; stage -\u0026gt; job Design plan -\u0026gt; code -\u0026gt; build -\u0026gt; test -\u0026gt; release -\u0026gt; deploy -\u0026gt; operate -\u0026gt; monitor -\u0026gt; plan Runner Executors Shell VirtualBox Docker Docker Machine Kubernetes Else\u0026hellip; References Gitlab CI/CD Gitlab Runner .gitlab-ci.yaml Runner Register gitlab-runner register\nAfter register concurrent = 1 check_interval = 0 [session_server] session_timeout = 1800 [[runners]] name = \u0026#34;public-shell\u0026#34; url = \u0026#34;https://gitlab.","tags":["Gitlab","introduction","slides","CI"],"title":"Gitlab-CI Introduction"},{"categories":["Docker"],"contents":"Docker Concept VM vs Container VM - Base on OS Container - Base on Application (Linux Kernel: Namespace and Cgroup) Client to Server Docker daemon - containerd, docker-containerd-shim, docker-runc Docker client - cli command docker cli -\u0026gt; docker daemon -\u0026gt; containerd -\u0026gt; runc -\u0026gt; namespace \u0026amp; cgroup Image Snapshots Container Read-Only processes on image Hub / Registry Store images References Docker —— 從入門到實踐 docker docs Docker commands Dockerfile ARG dist=\u0026#34;/tmp/password\u0026#34; ARG projectDir=\u0026#34;/password\u0026#34; FROM golang:1.16-alpine3.14 AS builder RUN apk add build-base upx ARG dist ARG projectDir WORKDIR ${projectDir} COPY . . RUN go build -trimpath -o main cmd/main.go RUN upx -9 -o ${dist} main FROM scratch ARG dist ENV TZ=Asia/Taipei COPY --from=builder ${dist} /usr/local/bin/password Dockerfile1 FROM alpine CMD [\u0026#34;nc\u0026#34;,\u0026#34;-l\u0026#34;,\u0026#34;12345\u0026#34;] Dockerfile2 FROM alpine CMD [\u0026#34;echo\u0026#34;,\u0026#34;DOCKER\u0026#34;] docker build command docker build . -t program docker build . -f Dockerfile -t test_mysql docker build . -t hello:v1.1 --build-arg dist=/tmp/hello --build-arg projectDir=/hello docker build . docker/status echo -e \u0026#34;${GREEN}Before build${RESET}\u0026#34; docker image ls docker build . -f docker/Dockerfile1 -t test1 docker build . -f docker/Dockerfile2 -t test2 docker image . docker/status echo -e \u0026#34;${GREEN}After build${RESET}\u0026#34; docker image ls docker run AND rm . docker/status echo -e \u0026#34;${GREEN}Run container1${RESET}\u0026#34; docker run -d --name container1 test1 echo -e \u0026#34;${GREEN}Run container2${RESET}\u0026#34; docker run -d --name container2 test2 echo -e \u0026#34;${GREEN}List alive containers${RESET}\u0026#34; docker ps echo -e \u0026#34;${GREEN}List all containers${RESET}\u0026#34; docker ps -a echo -e \u0026#34;${GREEN}Remove alive container${RESET}\u0026#34; docker rm -f container1 echo -e \u0026#34;${GREEN}List all containers${RESET}\u0026#34; docker ps -a echo -e \u0026#34;${GREEN}Remove exit container${RESET}\u0026#34; docker rm container2 echo -e \u0026#34;${GREEN}List all containers${RESET}\u0026#34; docker ps -a docker pull AND rmi . docker/status echo -e \u0026#34;${GREEN}List all image${RESET}\u0026#34; docker image ls echo -e \u0026#34;${GREEN}Pull alpine image${RESET}\u0026#34; docker pull alpine echo -e \u0026#34;${GREEN}List all image${RESET}\u0026#34; docker image ls docker rmi . docker/status echo -e \u0026#34;${GREEN}Remove alpine image${RESET}\u0026#34; docker rmi alpine echo -e \u0026#34;${GREEN}List all image${RESET}\u0026#34; docker image ls prune docker system prune -f --volumes docker history . docker/status echo -e \u0026#34;${GREEN}History of test1${RESET}\u0026#34; docker history test1 echo -e \u0026#34;${GREEN}History of mysql:8${RESET}\u0026#34; docker history mysql:8 Docker remote Edit service file # /lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock -H tcp://0.0.0.0:2375 Restart service systemctl daemon-reload systemctl restart docker Specify DOCKER_HOST . docker/status echo -e \u0026#34;${GREEN}List images on 192.168.185.9${RESET}\u0026#34; DOCKER_HOST=192.168.185.9:2375 docker images Docker-compose version: \u0026#34;3\u0026#34; services: svn: image: zeyanlin/svn environment: - LDAP_HOSTS=${LDAP_HOSTS} - LDAP_BASE_DN=${LDAP_BASE_DN} - LDAP_BIND_DN=${LDAP_BIND_DN} - LDAP_ADMIN_PASS=${LDAP_ADMIN_PASS} ports: - 8000:80 - 3690:3690 depends_on: - ldap ldap: image: zeyanlin/openldap environment: - LDAP_DOMAIN=${LDAP_DOMAIN} - LDAP_ADMIN_PASS=${LDAP_ADMIN_PASS} ports: - 389:389 - 636:636 php: image: zeyanlin/phpldapadmin environment: - LDAP_HOSTS=${LDAP_HOSTS} ports: - 80:80 depends_on: - ldap Env LDAP_HOSTS=ldap LDAP_DOMAIN=\u0026#34;knowhow.fun\u0026#34; LDAP_BASE_DN=\u0026#34;dc=knowhow,dc=fun\u0026#34; LDAP_BIND_DN=\u0026#34;cn=admin\u0026#34; LDAP_ADMIN_PASS=\u0026#34;123qwe\u0026#34; ","date":"September 17, 2021","hero":"/posts/20210917docker/docker.jpeg","permalink":"https://linzeyan.github.io/posts/20210917docker/","summary":"Docker Concept VM vs Container VM - Base on OS Container - Base on Application (Linux Kernel: Namespace and Cgroup) Client to Server Docker daemon - containerd, docker-containerd-shim, docker-runc Docker client - cli command docker cli -\u0026gt; docker daemon -\u0026gt; containerd -\u0026gt; runc -\u0026gt; namespace \u0026amp; cgroup Image Snapshots Container Read-Only processes on image Hub / Registry Store images References Docker —— 從入門到實踐 docker docs Docker commands Dockerfile ARG dist=\u0026#34;/tmp/password\u0026#34; ARG projectDir=\u0026#34;/password\u0026#34; FROM golang:1.","tags":["Docker","introduction","slides"],"title":"Docker Introduction"},{"categories":["Ansible"],"contents":"Getting to know Ansible. Outline Introduction Install Common modules Folder structure Conclusion Introduction 安裝部署工具、設定管理工具等\n同類型工具：Chef、Puppet、SaltStack\n不需要 Agent、透過 ssh\nLinux 有 python 即可 ( ssh port )\nWin 啟用 winrm 即可 ( 5986 port )\nhttps://docs.ansible.com/ansible/latest/user_guide/windows_winrm.html#inventory-options 資料夾結構簡單易懂、官方文件豐富易懂、模組多支援設備多、易撰寫\nInstall pip install ansible\npip3 install ansible yum install ansible\napt-get install ansible\napk add ansible\nCommon modules ping\nshell / command\nfile\nyum\nsystemd / service\ntemplate / copy\ndebug\nCommon modules - ping Common modules - shell / command Common modules - file Common modules - yum Common modules - systemd / service Common modules - template / copy Common modules - debug / register Folder structure Conclusion 選擇適合的 ansible ad-hoc ansible gitlab -m ping ansible gitlab -m shell -a 'rm -rf /' playbook role collection shell script python script others ","date":"September 26, 2020","hero":"/posts/20200926ansible/ansible.png","permalink":"https://linzeyan.github.io/posts/20200926ansible/","summary":"Getting to know Ansible. Outline Introduction Install Common modules Folder structure Conclusion Introduction 安裝部署工具、設定管理工具等\n同類型工具：Chef、Puppet、SaltStack\n不需要 Agent、透過 ssh\nLinux 有 python 即可 ( ssh port )\nWin 啟用 winrm 即可 ( 5986 port )\nhttps://docs.ansible.com/ansible/latest/user_guide/windows_winrm.html#inventory-options 資料夾結構簡單易懂、官方文件豐富易懂、模組多支援設備多、易撰寫\nInstall pip install ansible\npip3 install ansible yum install ansible\napt-get install ansible\napk add ansible\nCommon modules ping\nshell / command\nfile\nyum\nsystemd / service\ntemplate / copy\ndebug\nCommon modules - ping Common modules - shell / command Common modules - file Common modules - yum Common modules - systemd / service Common modules - template / copy Common modules - debug / register Folder structure Conclusion 選擇適合的 ansible ad-hoc ansible gitlab -m ping ansible gitlab -m shell -a 'rm -rf /' playbook role collection shell script python script others ","tags":["Ansible","introduction","slides"],"title":"Ansible Introduction"}]