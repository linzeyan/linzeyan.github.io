<!doctype html><html lang=en><head><title>Notes</title><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/application.780dc7a6fc8e42bf9fef490724bc6cbc57e759a0db2df60fcd517f9f667085ed.css integrity="sha256-eA3HpvyOQr+f70kHJLxsvFfnWaDbLfYPzVF/n2Zwhe0="><link rel=icon type=image/png href=/images/site/highlight.svg><link rel=alternate type=application/rss+xml href=https://linzeyan.github.io/notes/index.xml title=Ricky><meta property="og:title" content="Ricky"><meta property="og:type" content="website"><meta property="og:description" content="Ricky's Page."><meta property="og:image" content="/images/author/ava.jpg"><meta property="og:url" content="https://linzeyan.github.io/"><script defer src=https://static.cloudflareinsights.com/beacon.min.js data-cf-beacon='{"token": "27a0cd9f0e3b46909879cf99f7cc6878"}'></script><script integrity="sha256-DO4ugzEwhTW1Id1UIWn0gUJWaebCYOypeTit6LW4QB4=">let theme=localStorage.getItem("theme-scheme")||localStorage.getItem("darkmode:color-scheme")||"light";theme==="system"&&(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?theme="dark":theme="light"),document.documentElement.setAttribute("data-theme",theme)</script></head><body class="type-notes kind-section" data-bs-spy=scroll data-bs-target=#TableOfContents data-bs-offset=80><div class="container-fluid bg-secondary wrapper"><nav class="navbar navbar-expand-xl top-navbar shadow" id=top-navbar><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button>
<i data-feather=sidebar></i>
</button>
<a class=navbar-brand href=/><img src=/images/site/highlight.svg id=logo alt=Logo>
Ricky</a>
<button class="navbar-toggler navbar-light" id=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#top-nav-items aria-label=menu>
<i data-feather=menu></i></button><div class="collapse navbar-collapse dynamic-navbar" id=top-nav-items><ul class="nav navbar-nav ms-auto"><li class=nav-item><a class=nav-link href=/#home>Home</a></li><li class=nav-item><a class=nav-link href=/#about>About</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>More</a><div class=dropdown-menu aria-labelledby=navbarDropdown><a class=dropdown-item href=/#skills>Skills</a>
<a class=dropdown-item href=/#experiences>Experiences</a>
<a class=dropdown-item href=/#education>Education</a>
<a class=dropdown-item href=/#projects>Projects</a></div></li><div id=top-navbar-divider></div><li class=nav-item><a class=nav-link id=blog-link href=/posts>Posts</a></li><li class=nav-item><a class=nav-link id=note-link href=/notes>Notes</a></li><li class=nav-item><a class=nav-link href=https://linzeyan.github.io/activities>Activities</a></li><li class=nav-item><a class=nav-link href=https://transforms.pages.dev/>Transform</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=languageSelector role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false><span class="fi fi-us"></span>
English</a><div class=dropdown-menu aria-labelledby=languageSelector><a class="dropdown-item nav-link languages-item" href=/notes><span class="fi fi-us"></span>
English
</a><a class="dropdown-item nav-link languages-item" href=/zh-tw/notes><span class="fi fi-tw"></span>
Chinese</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme"></a><div id=themeMenu class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# data-scheme=light><img class=theme-icon src=/icons/sun-svgrepo-com.svg width=20 alt="Light Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=dark><img class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=system><img class=theme-icon src=/icons/computer-svgrepo-com.svg width=20 alt="System Theme"></a></div></li></ul></div></div><img src=/images/site/highlight.svg class=d-none id=main-logo alt=Logo>
<img src=/images/site/highlight.svg class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/notes data-filter=all>Notes</a></li><div class=subtree><li><i data-feather=plus-circle></i><a class=list-link href=/notes/aws/> AWS</a><ul><li><a class=list-link href=/notes/aws/command/ title=command>command</a></li><li><a class=list-link href=/notes/aws/configure/ title=configure>configure</a></li><li><a class=list-link href=/notes/aws/terraform/ title=terraform>terraform</a></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/notes/bash/> Bash</a><ul><li><a class=list-link href=/notes/bash/ansible/ title=ansible>ansible</a></li><li><a class=list-link href=/notes/bash/common/ title=common>common</a></li><li><a class=list-link href=/notes/bash/docker/ title=docker>docker</a></li><li><a class=list-link href=/notes/bash/file/ title=file>file</a></li><li><a class=list-link href=/notes/bash/git/ title=git>git</a></li><li><a class=list-link href=/notes/bash/gitlab/ title=gitlab>gitlab</a></li><li><a class=list-link href=/notes/bash/gpg/ title=gpg>gpg</a></li><li><a class=list-link href=/notes/bash/k8s/ title=k8s>k8s</a></li><li><a class=list-link href=/notes/bash/network/ title=network>network</a></li><li><a class=list-link href=/notes/bash/pandoc/ title=pandoc>pandoc</a></li><li><a class=list-link href=/notes/bash/redis/ title=redis>redis</a></li><li><a class=list-link href=/notes/bash/ssh/ title=ssh>ssh</a></li><li><a class=list-link href=/notes/bash/telegram/ title=telegram>telegram</a></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/notes/docs/> Docs</a><ul><li><a class=list-link href=/notes/docs/cloudflare/ title=cloudflare>cloudflare</a></li><li><a class=list-link href=/notes/docs/diagrams/ title=diagrams>diagrams</a></li><li><a class=list-link href=/notes/docs/docker/ title=docker>docker</a></li><li><a class=list-link href=/notes/docs/gitlab/ title=gitlab>gitlab</a></li><li><a class=list-link href=/notes/docs/linux/ title=linux>linux</a></li><li><a class=list-link href=/notes/docs/mermaid/ title=mermaid>mermaid</a></li><li><a class=list-link href=/notes/docs/network/ title=network>network</a></li><li><a class=list-link href=/notes/docs/nginx/ title=nginx>nginx</a></li><li><a class=list-link href=/notes/docs/vagrant/ title=vagrant>vagrant</a></li><li><a class=list-link href=/notes/docs/zabbix/ title=zabbix>zabbix</a></li></ul></li><li><a class=list-link href=/notes/elasticsearch/ title=Elasticsearch>Elasticsearch</a></li><li><i data-feather=plus-circle></i><a class=list-link href=/notes/gcp/> GCP</a><ul><li><a class=list-link href=/notes/gcp/command/ title=command>command</a></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/notes/go/> Go</a><ul><li><a class=list-link href=/notes/go/libraries/ title=Libraries>Libraries</a></li><li><i data-feather=plus-circle></i><a class=list-link href=/notes/go/questions/> Questions</a><ul><li><a class=list-link href=/notes/go/questions/array/ title=Array>Array</a></li><li><a class=list-link href=/notes/go/questions/channel/ title=Channel>Channel</a></li><li><a class=list-link href=/notes/go/questions/context/ title=Context>Context</a></li><li><a class=list-link href=/notes/go/questions/defer/ title=Defer>Defer</a></li><li><a class=list-link href=/notes/go/questions/goroutine/ title=Goroutine>Goroutine</a></li><li><a class=list-link href=/notes/go/questions/interface/ title=Interface>Interface</a></li><li><a class=list-link href=/notes/go/questions/iota/ title=Iota>Iota</a></li><li><a class=list-link href=/notes/go/questions/json/ title=JSON>JSON</a></li><li><a class=list-link href=/notes/go/questions/len/ title=Len>Len</a></li><li><a class=list-link href=/notes/go/questions/map/ title=Map>Map</a></li><li><a class=list-link href=/notes/go/questions/print/ title=Print>Print</a></li><li><a class=list-link href=/notes/go/questions/race/ title=Race>Race</a></li><li><a class=list-link href=/notes/go/questions/select/ title=Select>Select</a></li><li><a class=list-link href=/notes/go/questions/slice/ title=Slice>Slice</a></li><li><a class=list-link href=/notes/go/questions/variable/ title=Variable>Variable</a></li></ul></li><li><a class=list-link href=/notes/go/snippet/ title=Snippet>Snippet</a></li><li><a class=list-link href=/notes/go/tools/ title=Tools>Tools</a></li></ul></li><li><a class=list-link href=/notes/input-method/ title=Input-Method>Input-Method</a></li><li><a class=list-link href=/notes/server/ title=Server-Configs>Server-Configs</a></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid note-card-holder" id=note-card-holder><h1 id=深度学习识别验证码>深度学习识别验证码</h1><p>本项目致力于使用神经网络来识别各种验证码。</p><h1 id=特性>特性</h1><ul><li><strong>端到端，不需要做更多的图片预处理（比如图片字符切割、图片尺寸归一化、图片字符标记、字符图片特征提取）</strong></li><li><strong>验证码包括数字、大写字母、小写</strong></li><li><strong>采用自己生成的验证码来作为神经网络的训练集合、测试集合、预测集合</strong></li><li><strong>纯四位数字，验证码识别率高达 99.9999 %</strong></li><li><strong>四位数字 + 大写字符，验证码识别率约 96 %</strong></li><li><strong>深度学习框架pytorch + 验证码生成器ImageCaptcha</strong></li></ul><h1 id=原理>原理</h1><ul><li><p><strong>训练集合生成</strong></p><p>使用常用的 Python 验证码生成库 ImageCaptcha，生成 10w 个验证码，并且都自动标记好;
如果需要识别其他的验证码也同样的道理，寻找对应的验证码生成算法自动生成已经标记好的训练集合或者手动对标记，需要上万级别的数量，纯手工需要一定的时间，再或者可以借助一些网络的打码平台进行标记</p></li><li><p><strong>训练卷积神经网络</strong>
构建一个多层的卷积网络，进行多标签分类模型的训练
标记的每个字符都做 one-hot 编码
批量输入图片集合和标记数据，大概15个Epoch后，准确率已经达到 96% 以上</p></li></ul><h1 id=验证码识别率展示>验证码识别率展示</h1><p><img src=https://raw.githubusercontent.com/dee1024/pytorch-captcha-recognition/master/docs/number.png alt>
<img src=https://raw.githubusercontent.com/dee1024/pytorch-captcha-recognition/master/docs/number2.png alt></p><h1 id=快速开始>快速开始</h1><ul><li><p><strong>步骤一：10分钟环境安装</strong></p><p>Python2.7+ 、ImageCaptcha库(pip install captcha)、 Pytorch(参考官网http://pytorch.org)</p></li><li><p><strong>步骤二：生成验证码</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python captcha_gen.py
</span></span></code></pre></div><p>执行以上命令，会在目录 dataset/train/ 下生成多张验证码图片，图片已经标注好，数量可以是 1w、5w、10w，通过 captcha-gen.py 内的 count 参数设定</p></li><li><p><strong>步骤三：训练模型</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python captcha_train.py
</span></span></code></pre></div><p>使用步骤一生成的验证码图集合用CNN模型（在 catcha_cnn_model 中定义）进行训练，训练完成会生成文件 model.pkl</p></li><li><p><strong>步骤四：测试模型</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python captcha_test.py
</span></span></code></pre></div><p>可以在控制台，看到模型的准确率（如 95%） ，如果准确率较低，回到步骤一，生成更多的图片集合再次训练</p></li><li><p><strong>步骤五：使用模型做预测</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python captcha_predict.py
</span></span></code></pre></div><p>可以在控制台，看到预测输出的结果</p></li></ul><h1 id=贡献>贡献</h1><p>我们期待你的 pull requests !</p><h1 id=作者>作者</h1><ul><li><strong>Dee Qiu</strong> <a href=mailto:coolcooldee@gmail.com>coolcooldee@gmail.com</a></li></ul><h1 id=其它>其它</h1><ul><li><strong>Github项目交流QQ群</strong> 570997546</li></ul><h1 id=声明>声明</h1><p>本项目仅用于交流学习</p><h1 id=pytorch-captcha>pytorch-captcha</h1><p>使用pytorch搭建cnn识别验证码</p><p>数据集：
链接: <a href=https://pan.baidu.com/s/1pHSl-5nHJWazXVqda-2IcA target=_blank rel=noopener>https://pan.baidu.com/s/1pHSl-5nHJWazXVqda-2IcA</a> 提取码: mv3u 复制这段内容后打开百度网盘手机App，操作更方便哦</p><p>下载数据集后在根目录解压，运行train.py开始训练</p><hr><h1 id=pytorch入门实战之验证码识别>pytorch入门实战之验证码识别</h1><p>本文将使用pytorch框架训练一个四层卷积神经网络，用以识别四位数字字母区分大小的验证码。</p><h2 id=1-引言>1. 引言</h2><p>去年四六级查分时候我把准考证号忘了，准考证一时也找不到，最后是靠试准考证号试出来的，因为和我同一个考场的同学准考证号只有最后两位座位号不一样，一个考场不超过30人，遍历座位号就能试出来。</p><p>四六级查分系统有一个四位数字字母验证码，如果能够自动识别验证码，就能不断遍历准考证号查分了，不用手段输入验证码查分，效率大大提高，不知道淘宝上“忘记准考证号帮查四六级分”服务是不是这样做的。</p><h2 id=2-数据收集>2. 数据收集</h2><p>四六级查分网页链接为<a href=http://cet.neea.edu.cn/cet target=_blank rel=noopener>http://cet.neea.edu.cn/cet</a><br><img src=./pics/cet.png alt=四六级查分系统></p><p>首先按Fn+F12使用网页开发者工具抓包看一下验证码是如何请求，以及如何提交查询信息并返回结果。最好不要一次性把三条信息都输对，那样会直接跳到查询结果页，不方便查看提交查询的请求。</p><p><img src=./pics/query.png alt=查询的请求></p><p>可以很容易的找到提交请求的是一个post请求，请求地址为<code>http://cache.neea.edu.cn/cet/query</code>，请求参数有两个，分别是<code>data</code>和<code>v</code>，<code>data</code>是由一串固定字符和准考证号以及姓名组成，<code>v</code>则是验证码。通过构建查询请求，我们可以知道验证码是否输入正确。点击获取验证码按钮，可以抓包获取到验证码的请求，将验证码请求以及提交查询写成python代码如下：</p><pre><code>def get_captcha_img():
	ik = '123456789123456'
	rand = random.random()
	img_path = '{}/{}.png'.format(false_dir, rand)
	imgs_url = 'http://cache.neea.edu.cn/Imgs.do?c=CET&amp;ik={}&amp;t={}'.format(ik, 
	                                                      rand)
	headers = {'Referer': 'http://cet.neea.edu.cn/cet'}
	resp = sess.get(imgs_url, headers=headers)
	img_url = re.findall(r'&quot;([^&quot;]*)?&quot;', resp.text)[0]
	img_resp = sess.get(img_url, headers=headers)
	with open(img_path, 'wb') as f:
	    f.write(img_resp.content)
	return img_path  

def check_captcha(v):
	query_url = 'http://cache.neea.edu.cn/cet/query'
	data = {'data': 'CET4_181_DANGCI,123456789123456,萧炎',
	        'v': v}
	headers = {'Referer': 'http://cet.neea.edu.cn/cet'}
	resp = sess.post(query_url, headers=headers, data=data)
	#    print(resp.text)
	if '抱歉，验证码错误！' in resp.text:
    	return False
	else:
    	return True
</code></pre><p>结合以上请求验证码以及提交查询信息判断验证码是否正确的方法，再通过打码平台，可以获得带有正确标记的验证码图片。
使用上述方法，我获得了1181张带有标注的验证码，宽和高为（180，100），将其分为训练集与测试集，训练集为800张，测试及381张。我看过的其他使用卷积神经网络识别验证码的文章，使用的训练集数量多达几千上万张，大多都是自己用程序生成的，本文使用打码平台标记的验证码，就不要求那么大的数据集了，但也能达到满意的效果。</p><p>还值得一提的是，使用打码平台标注验证码，成功标注了1181张外，还有将近四百张验证码识别失败，粗略估计，这个打码平台准确率在75%左右。</p><p><img src=./pics/traindata.png alt=训练集></p><h2 id=3-cnn模型搭建>3. CNN模型搭建</h2><p>CNN主要由卷积层，池化层，激活函数组成，再加上一个BatchNorm，BatchNorm叫做批规范化，可以加速模型的收敛速度。</p><p>模型代码如下：</p><pre><code>import torch.nn as nn

class CNN(nn.Module):
	def __init__(self, num_class=36, num_char=4):
	    super(CNN, self).__init__()
	    self.num_class = num_class
	    self.num_char = num_char
	    self.conv = nn.Sequential(
	            #batch*3*180*100
	            nn.Conv2d(3, 16, 3, padding=(1, 1)),
	            nn.MaxPool2d(2, 2),
	            nn.BatchNorm2d(16),
	            nn.ReLU(),
	            #batch*16*90*50
	            nn.Conv2d(16, 64, 3, padding=(1, 1)),
	            nn.MaxPool2d(2, 2),
	            nn.BatchNorm2d(64),
	            nn.ReLU(),
	            #batch*64*45*25
	            nn.Conv2d(64, 512, 3, padding=(1, 1)),
	            nn.MaxPool2d(2, 2),
	            nn.BatchNorm2d(512),
	            nn.ReLU(),
	            #batch*512*22*12
	            nn.Conv2d(512, 512, 3, padding=(1, 1)),
	            nn.MaxPool2d(2, 2),
	            nn.BatchNorm2d(512),
	            nn.ReLU(),
	            #batch*512*11*6
	            )
	    self.fc = nn.Linear(512*11*6, self.num_class*self.num_char)
	    
	def forward(self, x):
	    x = self.conv(x)
	    x = x.view(-1, 512*11*6)
	    x = self.fc(x)
	    return x
</code></pre><p>nn.Sequential()可以看作模块的有序容器，可以方便快捷的搭建神经网络。<br>网络的输入是一个shape为<code>[batch, 3, 180, 100]</code>的张量，batch代表的是一个批次图片数量，3代表输入的图片是3通道的，即RGB，180和100则分别代表图片的宽和高。</p><p>主要的结构如下：</p><ol><li><p>第一个卷积层<code>nn.Conv2d(3, 16, 3, padding=(1, 1))</code>，参数分别对应着输入的通道数3，输出通道数16，卷积核大小为3（长宽都为3），padding为（1， 1）可以保证输入输出的长宽不变。shape为<code>[batch, 3, 180, 100]</code>的张量通过这个卷积层，输出一个shape为<code>[batch, 16, 180, 100]</code>的张量。</p></li><li><p>接着一个最大池化层<code>nn.MaxPool2d(2, 2)</code>，参数分别对应着池化窗口大小为2（长宽都为2），步长为3. 输出的长宽为输入的一半，如果长宽为奇数的话则补边。输入一个shape为<code>[batch, 16, 180, 100]</code>的张量，输出为一个shape为<code>[batch, 16, 90, 50]</code>的张量。</p></li><li><p>批规范层<code>nn.BatchNorm2d(16)</code>，16为输入张量的通道数。</p></li><li><p>激活函数<code>nn.ReLu()</code>，就是把小于0的值置0，大于0的值不变，使用激活函数是为了引入非线性，让模型可以拟合更复杂的函数。</p></li></ol><p>经过4组如上结构的卷积后，得到一个shape为<code>[batch, 512, 11, 6]</code>的张量，<code>x.view(-1, 512*11*6)</code>将改变张量的shape为<code>[batch, 512*11*6]</code>，再用一个<code>[512*11*6, num_class*num_char]</code>的全连接层映射为一个<code>[batch, num_class*num_char]</code>张量，这个就是模型的输出，其中<code>num_class</code>代表字符的种类数量，<code>num_char</code>代表一张验证码图片含有的字符数量，分别为36与4。</p><h2 id=4-数据加载>4. 数据加载</h2><p>pytorch有非常方便高效的数据加载模块&ndash;Dataset和DataLoader。<br>Dataset是数据样本的封装，可以很方便的读取数据。实现一个Dataset的子类，需要重写<code>__len__</code>和<code>__getitem__</code>方法，<code>__len__</code>需要返回整个数据集的大小，<code>__getitem__</code>提供一个整数索引参数，一个样本数据（一个图片张量和一个标签张量）。<br>验证码图片的Dataset代码如下：</p><pre><code>class CaptchaData(Dataset):
	def __init__(self, data_path, num_class=36, num_char=4, 
	             transform=None, target_transform=None, alphabet=alphabet):
	    super(Dataset, self).__init__()
	    self.data_path = data_path
	    self.num_class = num_class
	    self.num_char = num_char
	    self.transform = transform
	    self.target_transform = target_transform
	    self.alphabet = alphabet
	    self.samples = make_dataset(self.data_path, self.alphabet, 
	                                self.num_class, self.num_char)
	
	def __len__(self):
	    return len(self.samples)
	
	def __getitem__(self, index):
	    img_path, target = self.samples[index]
	    img = img_loader(img_path)
	    if self.transform is not None:
	    	img = self.transform(img)
	    if self.target_transform is not None:
        	target = self.target_transform(target)
    	return img, torch.Tensor(target)  
</code></pre><p>其中<code>make_dataset</code>为读取图片路径和标签的函数，返回<code>[(img_path, target), (img_path, target), ...]</code>的数据形式。<code>img_loader</code>为读取图片的函数，并且转换成RGB三通道。
这两个函数具体实现如下：</p><pre><code>def img_loader(img_path):
    img = Image.open(img_path)
    return img.convert('RGB')

def make_dataset(data_path, alphabet, num_class, num_char):
    img_names = os.listdir(data_path)
    samples = []
    for img_name in img_names:
        img_path = os.path.join(data_path, img_name)
        target_str = img_name.split('.')[0]
        assert len(target_str) == num_char
        target = []
        for char in target_str:
            vec = [0] * num_class
            vec[alphabet.find(char)] = 1
            target += vec
        samples.append((img_path, target))
    return samples  
</code></pre><p>DataLoader是Dataset的进一步封装，Dataset每次通过<code>__getitem__</code>方法取到的是一个样本，经过DataLoader封装为dataloader后，每次取的是一个batch大小的样本批次。</p><pre><code>transforms = Compose([ToTensor()])
train_dataset = CaptchaData('./data/train', transform=transforms)
train_data_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, 
                         shuffle=True, drop_last=True)
test_data = CaptchaData('./data/test', transform=transforms)
test_data_loader = DataLoader(test_data, batch_size=batch_size, 
                              num_workers=0, shuffle=True, drop_last=True)
</code></pre><p><code>transforms</code>是数据预处理操作，一般数据增强就通过transform实现，可以随机亮度，随机翻转，随机缩放等等。此处只使用了<code>ToTensor()</code>，将<code>PIL.Image</code>对象转换成Tensor。</p><h2 id=5-训练>5. 训练</h2><p>训练网络的一般流程为：</p><ol><li>定义网络</li><li>定义优化器<code>optimizer</code>和损失函数<code>criterion</code></li><li>遍历<code>dataloader</code>，每次取一个batch训练。计算loss，将优化器梯度置零，loss向后传播，计算梯度，优化器更新参数。</li><li>训练集训练完一个epoch后，使用测试集计算下准确率。</li><li>保存模型<br>主要代码如下：</li></ol><pre tabindex=0><code>    cnn = CNN()
    if torch.cuda.is_available():
        cnn.cuda()
    optimizer = torch.optim.Adam(cnn.parameters(), lr=base_lr)
    criterion = nn.MultiLabelSoftMarginLoss()
    
    for epoch in range(max_epoch):
        cnn.train()
        for img, target in train_data_loader:
            img = Variable(img)
            target = Variable(target)
            if torch.cuda.is_available():
                img = img.cuda()
                target = target.cuda()
            output = cnn(img)
            loss = criterion(output, target)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        
        loss_history = []
        acc_history = []
        cnn.eval()
        for img, target in test_data_loader:
            img = Variable(img)
            target = Variable(target)
            if torch.cuda.is_available():
                img = img.cuda()
                target = target.cuda()
            output = cnn(img)
            
            acc = calculat_acc(output, target)
            acc_history.append(acc)
            loss_history.append(float(loss))
        torch.save(cnn.state_dict(), model_path)  
</code></pre><p>其中，<code>cnn.train()</code>将网络切换到训练状态，<code>cnn.eval()</code>将网络切换到模型评估状态，这两者的差别主要体现在dropout和batchnorm层中，模型评估状态下，将不会启用dropout层，batchnrom不会更新均值和标准差。<code>cnn.cuda()</code>将数据张量分配到cuda设备上（英伟达显卡），加快运算速度。
损失函数使用的是<code>nn.MultiLabelSoftMarginLoss()</code>，多分类多标签损失函数。每个类别有多个标签，集每张验证码有四个字符。</p><p>选择accuracy（预测准确率）做为模型的评估指标，需要再编写一个计算准确率的函数：</p><pre><code>def calculat_acc(output, target):
	output, target = output.view(-1, 36), target.view(-1, 36)
	output = nn.functional.softmax(output, dim=1)
	output = torch.argmax(output, dim=1)
	target = torch.argmax(target, dim=1)
	output, target = output.view(-1, 4), target.view(-1, 4)
	correct_list = []
	for i, j in zip(target, output):
	    if torch.equal(i, j):
	        correct_list.append(1)
	    else:
	        correct_list.append(0)
	acc = sum(correct_list) / len(correct_list)
	return acc  
</code></pre><p>训练结果：<br><img src=./pics/training.png alt=训练结果></p><p>最终训练了五十几个epoch后，测试集准确率最高达75%，训练集已过拟合达100%。<br>再将验证码打印出来，预测与实际标签对比：
<img src=./pics/display.png alt></p><h2 id=6-结语>6. 结语</h2><p>仅使用800张验证码图片做为训练集，就能最终达到75%的准确率，效果还是比较满意的，已经和打码平台差不多了。要想进一步的提高准确率，需要扩充数据集。可以将已经训练好，准确率达到75%的模型代替打码平台，去获取更多标注好的验证码。数据集充分的情况下，准确率达到90%是比较容易的。</p><div class=note-card><div class=item><h5 class=note-title><span>Data too large</span></h5><div class=card><div class=card-body><p><code>[parent] Data too large, data for [&lt;http_request>] would be [123848638/118.1mb], which is larger than the limit of [123273216/117.5mb], real usage: [120182112/114.6mb], new bytes reserved: [3666526/3.4mb]</code></p><p><a href=https://www.elastic.co/guide/en/elasticsearch/reference/7.14/fix-common-cluster-issues.html#circuit-breaker-errors target=_blank rel=noopener>https://www.elastic.co/guide/en/elasticsearch/reference/7.14/fix-common-cluster-issues.html#circuit-breaker-errors</a></p></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>Data</span></h5><div class=card><div class=card-body><ul><li>ML<ul><li><a href=https://github.com/sjwhitworth/golearn target=_blank rel=noopener>https://github.com/sjwhitworth/golearn</a></li><li><a href=https://github.com/gorse-io/gorse target=_blank rel=noopener>https://github.com/gorse-io/gorse</a></li><li><a href=https://github.com/gorgonia/gorgonia target=_blank rel=noopener>https://github.com/gorgonia/gorgonia</a></li><li><a href=https://github.com/cdipaolo/goml target=_blank rel=noopener>https://github.com/cdipaolo/goml</a></li><li><a href=https://github.com/galeone/tfgo target=_blank rel=noopener>https://github.com/galeone/tfgo</a></li></ul></li><li>data<ul><li><a href=https://github.com/gonum/gonum target=_blank rel=noopener>https://github.com/gonum/gonum</a></li><li><a href=https://github.com/gonum/plot target=_blank rel=noopener>https://github.com/gonum/plot</a></li><li><a href=https://github.com/vdobler/chart target=_blank rel=noopener>https://github.com/vdobler/chart</a></li><li><a href=https://github.com/rocketlaunchr/dataframe-go target=_blank rel=noopener>https://github.com/rocketlaunchr/dataframe-go</a></li><li><a href=https://github.com/cpmech/gosl target=_blank rel=noopener>https://github.com/cpmech/gosl</a></li><li><a href=https://github.com/montanaflynn/stats target=_blank rel=noopener>https://github.com/montanaflynn/stats</a></li><li><a href=https://github.com/nytlabs/streamtools target=_blank rel=noopener>https://github.com/nytlabs/streamtools</a></li></ul></li></ul></div></div></div></div></div><div class=paginator><ul class="pagination pagination-default"><li class=page-item><a href=/notes/ aria-label=First class=page-link role=button><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/notes/page/5/ aria-label=Previous class=page-link role=button><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a href=/notes/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/notes/page/4/ aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/notes/page/5/ aria-label="Page 5" class=page-link role=button>5</a></li><li class="page-item active"><a aria-current=page aria-label="Page 6" class=page-link role=button>6</a></li><li class=page-item><a href=/notes/page/7/ aria-label="Page 7" class=page-link role=button>7</a></li><li class=page-item><a href=/notes/page/7/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/notes/page/7/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-start"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://linzeyan.github.io/#about>About</a></li><li class=nav-item><a class=smooth-scroll href=https://linzeyan.github.io/#skills>Skills</a></li><li class=nav-item><a class=smooth-scroll href=https://linzeyan.github.io/#experiences>Experiences</a></li><li class=nav-item><a class=smooth-scroll href=https://linzeyan.github.io/#education>Education</a></li><li class=nav-item><a class=smooth-scroll href=https://linzeyan.github.io/#projects>Projects</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><a href=mailto:zeyanlin@outlook.com target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>zeyanlin@outlook.com</span></a></li><li><a href=https://github.com/linzeyan target=_blank rel=noopener><span><i class="fab fa-github"></i></span> <span>linzeyan</span></a></li><li><a href=https://www.strava.com/athletes/rickylin target=_blank rel=noopener><span><i class="fab fa-fab fa-strava"></i></span> <span>Ricky</span></a></li><li><a href=https://t.me/ricky_lin target=_blank rel=noopener><span><i class="fab fa-fab fa-telegram"></i></span> <span>Ricky</span></a></li></ul></div></div></div></footer><script src=/application.eed5c22001d7c9cc6de7d8db62219c198319957fa017da141928bee1c40883b4.js integrity="sha256-7tXCIAHXycxt59jbYiGcGYMZlX+gF9oUGSi+4cQIg7Q=" defer></script></body></html>